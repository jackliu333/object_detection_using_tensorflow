{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa8221f-21c5-4d11-9a14-3430af0b2a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision.models import detection, resnet50, ResNet50_Weights\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc75a738-e9c9-4b95-9229-0540fe0a2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = {\n",
    "    # determine the current device and based on that set the pin memory\n",
    "    # flag\n",
    "    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    # specify ImageNet mean and standard deviation\n",
    "    \"IMG_MEAN\": [0.485, 0.456, 0.406],\n",
    "    \"IMG_STD\": [0.229, 0.224, 0.225],\n",
    "    \"MC_DROPOUT_ENABLED\": False,  # Switch to enable/disable MC Dropout for confidence score\n",
    "    \"NUM_DROPOUT_RUNS\": 3,\n",
    "    \"CONFIDENCE_THRESHOLD\": 0,\n",
    "    \"BIG_MODEL_IMG_SIZE\": 320,\n",
    "    \"SMALL_MODEL_IMG_SIZE\": 60,\n",
    "    \"MEAN_PRIOR\": -15,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e0656-aacb-422f-af50-38126e838d71",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Big model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce9ac3-24b6-4306-ae9f-b4d73e4162b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f349c065-57dd-47f2-9043-a91308360219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadResNet_BigModel(nn.Module):\n",
    "    def __init__(self, num_classes_prdtype, num_classes_weight, num_classes_halal, num_classes_healthy):\n",
    "        super(MultiHeadResNet_BigModel, self).__init__()\n",
    "        self.base_model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        num_ftrs = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Identity()\n",
    "\n",
    "        # Define custom fully connected layers for each prediction head\n",
    "        self.fc_prdtype = nn.Linear(num_ftrs, num_classes_prdtype)\n",
    "        self.fc_weight = nn.Linear(num_ftrs, num_classes_weight)\n",
    "        self.fc_halal = nn.Linear(num_ftrs, num_classes_halal)\n",
    "        self.fc_healthy = nn.Linear(num_ftrs, num_classes_healthy)\n",
    "        self.fc_bbox = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        prdtype = self.fc_prdtype(x)\n",
    "        weight = self.fc_weight(x)\n",
    "        halal = self.fc_halal(x)\n",
    "        healthy = self.fc_healthy(x)\n",
    "        box = self.fc_bbox(x)\n",
    "        return prdtype, weight, halal, healthy, box\n",
    "\n",
    "    \n",
    "# load label encoder \n",
    "def load_label_encoder_big_model():\n",
    "    le_prdtype = pickle.loads(open(\"NN_model/regularized/le_prdtype.pickle\", \"rb\").read())\n",
    "    le_weight = pickle.loads(open(\"NN_model/regularized/le_weight.pickle\", \"rb\").read())\n",
    "    le_halal = pickle.loads(open(\"NN_model/regularized/le_halal.pickle\", \"rb\").read())\n",
    "    le_healthy = pickle.loads(open(\"NN_model/regularized/le_healthy.pickle\", \"rb\").read())\n",
    "    \n",
    "    return le_prdtype, le_weight, le_halal, le_healthy\n",
    "\n",
    "le_prdtype, le_weight, le_halal, le_healthy = load_label_encoder_big_model()\n",
    "\n",
    "# Load the trained MultiHeadResNet model\n",
    "def load_model():\n",
    "    # Verify the number of classes for each label\n",
    "    num_classes_prdtype = len(le_prdtype.classes_)\n",
    "    num_classes_weight = len(le_weight.classes_)\n",
    "    num_classes_halal = len(le_halal.classes_)\n",
    "    num_classes_healthy = len(le_healthy.classes_)\n",
    "    # print(num_classes_prdtype)\n",
    "    # print(num_classes_healthy)\n",
    "\n",
    "    custom_resnet_model = MultiHeadResNet_BigModel(\n",
    "        num_classes_prdtype=num_classes_prdtype,\n",
    "        num_classes_weight=num_classes_weight,\n",
    "        num_classes_halal=num_classes_halal,\n",
    "        num_classes_healthy=num_classes_healthy\n",
    "    )\n",
    "\n",
    "    model_path = 'NN_model/regularized/multi_head_model.pth'\n",
    "    # print(\"test1\")\n",
    "    if os.path.exists(model_path):\n",
    "        custom_resnet_model.load_state_dict(torch.load(model_path, map_location=CONFIGS['DEVICE']))\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    # print(\"test2\")\n",
    "    custom_resnet_model.to(CONFIGS['DEVICE'])\n",
    "    custom_resnet_model.eval()\n",
    "    return custom_resnet_model\n",
    "\n",
    "big_model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa0d993-323b-42cd-b742-bc571f747246",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scoring on main imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b29399c3-77e0-488c-afee-39967ddb641a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>CorrectTotalLabel</th>\n",
       "      <th>ProductType_AdultMilk</th>\n",
       "      <th>ProductType_BabyMilkPowder</th>\n",
       "      <th>ProductType_Babyfood</th>\n",
       "      <th>ProductType_BeehoonVermicelli</th>\n",
       "      <th>ProductType_BiscuitsCrackersCookies</th>\n",
       "      <th>ProductType_Book</th>\n",
       "      <th>ProductType_BreakfastCereals</th>\n",
       "      <th>ProductType_CannedBakedBeans</th>\n",
       "      <th>...</th>\n",
       "      <th>Weight_400-499g</th>\n",
       "      <th>Weight_500-599g</th>\n",
       "      <th>Weight_600-699g</th>\n",
       "      <th>Weight_700-799g</th>\n",
       "      <th>Weight_800-899g</th>\n",
       "      <th>Weight_900-999g</th>\n",
       "      <th>HalalStatus_Halal</th>\n",
       "      <th>HalalStatus_NonHalal</th>\n",
       "      <th>HealthStatus_Healthy</th>\n",
       "      <th>HealthStatus_NonHealthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4351699431915_.pic.jpg</td>\n",
       "      <td>BiscuitsCrackersCookies_1-99g_NonHalal_NonHealthy</td>\n",
       "      <td>-2.980538</td>\n",
       "      <td>-3.308298</td>\n",
       "      <td>-2.595321</td>\n",
       "      <td>-3.625588</td>\n",
       "      <td>7.027510</td>\n",
       "      <td>-2.422827</td>\n",
       "      <td>-3.109597</td>\n",
       "      <td>-3.762012</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.151647</td>\n",
       "      <td>-2.482224</td>\n",
       "      <td>-2.107722</td>\n",
       "      <td>-1.575631</td>\n",
       "      <td>-1.180781</td>\n",
       "      <td>-1.751149</td>\n",
       "      <td>-2.099822</td>\n",
       "      <td>2.551977</td>\n",
       "      <td>-1.884070</td>\n",
       "      <td>1.546358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20231222_0586.jpg</td>\n",
       "      <td>Salt_500-599g_Halal_NonHealthy</td>\n",
       "      <td>-3.421535</td>\n",
       "      <td>-3.006071</td>\n",
       "      <td>-4.226384</td>\n",
       "      <td>-2.194710</td>\n",
       "      <td>-2.810256</td>\n",
       "      <td>-3.388601</td>\n",
       "      <td>-2.844199</td>\n",
       "      <td>-3.704459</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.613168</td>\n",
       "      <td>5.821902</td>\n",
       "      <td>-1.478095</td>\n",
       "      <td>-1.162005</td>\n",
       "      <td>-1.946283</td>\n",
       "      <td>-2.333418</td>\n",
       "      <td>1.760830</td>\n",
       "      <td>-1.721149</td>\n",
       "      <td>-1.842590</td>\n",
       "      <td>1.323182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_5338_jpeg.rf.aea9f974feca334ffdde3f65c92c0...</td>\n",
       "      <td>BiscuitsCrackersCookies_100-199g_Halal_NonHealthy</td>\n",
       "      <td>-4.228448</td>\n",
       "      <td>-3.889838</td>\n",
       "      <td>-3.847276</td>\n",
       "      <td>-3.357298</td>\n",
       "      <td>6.261020</td>\n",
       "      <td>-3.785935</td>\n",
       "      <td>-2.579459</td>\n",
       "      <td>-4.610152</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.630664</td>\n",
       "      <td>-1.779001</td>\n",
       "      <td>-1.133155</td>\n",
       "      <td>-2.384766</td>\n",
       "      <td>-1.569428</td>\n",
       "      <td>-2.810149</td>\n",
       "      <td>1.871931</td>\n",
       "      <td>-2.075112</td>\n",
       "      <td>-2.079360</td>\n",
       "      <td>1.580235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_5598_jpeg.rf.9c5c4f3282b0276f142eb16136e8a...</td>\n",
       "      <td>InstantNoodles_400-499g_Halal_NonHealthy</td>\n",
       "      <td>-2.723399</td>\n",
       "      <td>-2.619614</td>\n",
       "      <td>-3.779717</td>\n",
       "      <td>-2.394722</td>\n",
       "      <td>-0.482245</td>\n",
       "      <td>-2.498887</td>\n",
       "      <td>-2.311876</td>\n",
       "      <td>-3.451860</td>\n",
       "      <td>...</td>\n",
       "      <td>6.744938</td>\n",
       "      <td>-2.034772</td>\n",
       "      <td>-1.241825</td>\n",
       "      <td>-1.376141</td>\n",
       "      <td>-1.608180</td>\n",
       "      <td>-1.969442</td>\n",
       "      <td>1.224781</td>\n",
       "      <td>-1.371373</td>\n",
       "      <td>-1.733410</td>\n",
       "      <td>1.203111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240123_5_1072(2).jpg</td>\n",
       "      <td>OtherBakingNeeds_500-599g_Halal_NonHealthy</td>\n",
       "      <td>-1.977953</td>\n",
       "      <td>-4.394702</td>\n",
       "      <td>-4.936197</td>\n",
       "      <td>-1.883358</td>\n",
       "      <td>-2.965535</td>\n",
       "      <td>-4.753546</td>\n",
       "      <td>-3.486364</td>\n",
       "      <td>-5.080432</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.218506</td>\n",
       "      <td>7.024712</td>\n",
       "      <td>-0.215257</td>\n",
       "      <td>-1.426052</td>\n",
       "      <td>-2.467675</td>\n",
       "      <td>-2.280322</td>\n",
       "      <td>1.363083</td>\n",
       "      <td>-1.556793</td>\n",
       "      <td>-1.938033</td>\n",
       "      <td>1.801286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Filename  \\\n",
       "0                             4351699431915_.pic.jpg   \n",
       "1                                  20231222_0586.jpg   \n",
       "2  IMG_5338_jpeg.rf.aea9f974feca334ffdde3f65c92c0...   \n",
       "3  IMG_5598_jpeg.rf.9c5c4f3282b0276f142eb16136e8a...   \n",
       "4                             20240123_5_1072(2).jpg   \n",
       "\n",
       "                                   CorrectTotalLabel  ProductType_AdultMilk  \\\n",
       "0  BiscuitsCrackersCookies_1-99g_NonHalal_NonHealthy              -2.980538   \n",
       "1                     Salt_500-599g_Halal_NonHealthy              -3.421535   \n",
       "2  BiscuitsCrackersCookies_100-199g_Halal_NonHealthy              -4.228448   \n",
       "3           InstantNoodles_400-499g_Halal_NonHealthy              -2.723399   \n",
       "4         OtherBakingNeeds_500-599g_Halal_NonHealthy              -1.977953   \n",
       "\n",
       "   ProductType_BabyMilkPowder  ProductType_Babyfood  \\\n",
       "0                   -3.308298             -2.595321   \n",
       "1                   -3.006071             -4.226384   \n",
       "2                   -3.889838             -3.847276   \n",
       "3                   -2.619614             -3.779717   \n",
       "4                   -4.394702             -4.936197   \n",
       "\n",
       "   ProductType_BeehoonVermicelli  ProductType_BiscuitsCrackersCookies  \\\n",
       "0                      -3.625588                             7.027510   \n",
       "1                      -2.194710                            -2.810256   \n",
       "2                      -3.357298                             6.261020   \n",
       "3                      -2.394722                            -0.482245   \n",
       "4                      -1.883358                            -2.965535   \n",
       "\n",
       "   ProductType_Book  ProductType_BreakfastCereals  \\\n",
       "0         -2.422827                     -3.109597   \n",
       "1         -3.388601                     -2.844199   \n",
       "2         -3.785935                     -2.579459   \n",
       "3         -2.498887                     -2.311876   \n",
       "4         -4.753546                     -3.486364   \n",
       "\n",
       "   ProductType_CannedBakedBeans  ...  Weight_400-499g  Weight_500-599g  \\\n",
       "0                     -3.762012  ...        -1.151647        -2.482224   \n",
       "1                     -3.704459  ...        -1.613168         5.821902   \n",
       "2                     -4.610152  ...        -1.630664        -1.779001   \n",
       "3                     -3.451860  ...         6.744938        -2.034772   \n",
       "4                     -5.080432  ...        -1.218506         7.024712   \n",
       "\n",
       "   Weight_600-699g  Weight_700-799g  Weight_800-899g  Weight_900-999g  \\\n",
       "0        -2.107722        -1.575631        -1.180781        -1.751149   \n",
       "1        -1.478095        -1.162005        -1.946283        -2.333418   \n",
       "2        -1.133155        -2.384766        -1.569428        -2.810149   \n",
       "3        -1.241825        -1.376141        -1.608180        -1.969442   \n",
       "4        -0.215257        -1.426052        -2.467675        -2.280322   \n",
       "\n",
       "   HalalStatus_Halal  HalalStatus_NonHalal  HealthStatus_Healthy  \\\n",
       "0          -2.099822              2.551977             -1.884070   \n",
       "1           1.760830             -1.721149             -1.842590   \n",
       "2           1.871931             -2.075112             -2.079360   \n",
       "3           1.224781             -1.371373             -1.733410   \n",
       "4           1.363083             -1.556793             -1.938033   \n",
       "\n",
       "   HealthStatus_NonHealthy  \n",
       "0                 1.546358  \n",
       "1                 1.323182  \n",
       "2                 1.580235  \n",
       "3                 1.203111  \n",
       "4                 1.801286  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_imgs_results_big_model = pd.read_csv(\"NN_model/regularized/main_imgs_results_big_model.csv\")\n",
    "main_imgs_results_big_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f98391a-f54d-4251-a8c3-80daa4560e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the current column names to a list\n",
    "new_columns = main_imgs_results_big_model.columns.tolist()\n",
    "\n",
    "# Modify the first two elements\n",
    "new_columns[0] = 'filepath'\n",
    "new_columns[1] = 'label'\n",
    "\n",
    "# Assign the modified list of column names back to the DataFrame\n",
    "main_imgs_results_big_model.columns = new_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a8c1140-589c-4e62-812d-432b1e1b28bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 98)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_imgs_results_big_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79855889-bc7b-4ac6-83b0-21ff404a1220",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scoring on new imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1638f976-5416-43be-9e88-db876766869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_imgs_df = pd.read_csv(\"GPT_model/chatgpt_prediction.csv\")\n",
    "# new_imgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ff0834-2729-458c-a450-ebab96889095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms_test = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=CONFIGS['IMG_MEAN'], std=CONFIGS['IMG_STD'])\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e01814b1-4a72-44aa-9c3e-6bd08ff5a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_df = pd.read_csv(\"../../master_list.csv\")\n",
    "# master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cf6320c-d0c1-4ed6-940c-9b0b74b5b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_imgs_results_big_model = []  # List to store the results\n",
    "\n",
    "# for idx, row in new_imgs_df.iterrows():\n",
    "#     image_path = \"../../all_images/\" + row['img_filename']\n",
    "#     frame = cv2.imread(image_path)\n",
    "\n",
    "#     # Preprocessing steps\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     frame = cv2.resize(frame, (CONFIGS['BIG_MODEL_IMG_SIZE'], CONFIGS['BIG_MODEL_IMG_SIZE']))\n",
    "#     frame = frame.transpose((2, 0, 1))\n",
    "#     frame = torch.from_numpy(frame).float()\n",
    "#     frame = transforms_test(frame).unsqueeze(0).to(CONFIGS['DEVICE'])\n",
    "\n",
    "#     # Perform prediction\n",
    "#     with torch.no_grad():\n",
    "#         out1, out2, out3, out4, _ = big_model(frame)\n",
    "\n",
    "#     # reference the correct label from master list\n",
    "#     tmp_correct_label = master_df.loc[master_df['filepath'] == row['img_filename'], 'label'].iloc[0]\n",
    "        \n",
    "#     # Extract and store the results\n",
    "#     prediction_row = [row['img_filename'], tmp_correct_label]\n",
    "#     prediction_row.extend(out1.cpu().numpy().flatten())\n",
    "#     prediction_row.extend(out2.cpu().numpy().flatten())\n",
    "#     prediction_row.extend(out3.cpu().numpy().flatten())\n",
    "#     prediction_row.extend(out4.cpu().numpy().flatten())\n",
    "#     new_imgs_results_big_model.append(prediction_row)\n",
    "\n",
    "\n",
    "# # Define column names for the new DataFrame\n",
    "# column_names = ['filepath', 'label']\n",
    "# big_model_pred_col_name_original = main_imgs_results_big_model.columns[2:].tolist()\n",
    "# column_names += big_model_pred_col_name_original\n",
    "\n",
    "# # Create the DataFrame\n",
    "# new_imgs_results_big_model = pd.DataFrame(new_imgs_results_big_model, columns=column_names)\n",
    "# new_imgs_results_big_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64815a97-84b8-4fc9-b2e1-1e0488b944f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_imgs_results_big_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe5621-33fa-440c-8451-43ce13bcd1eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## All scorings from big model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6720b1d-00d1-4f93-8b73-c52711f06664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_imgs_results_big_model['img_type'] = \"existing\"\n",
    "# new_imgs_results_big_model['img_type'] = \"new\"\n",
    "# all_imgs_results_big_model = pd.concat([main_imgs_results_big_model, new_imgs_results_big_model], axis=0)\n",
    "# all_imgs_results_big_model.reset_index(drop=True, inplace=True)\n",
    "# all_imgs_results_big_model.head()\n",
    "all_imgs_results_big_model = main_imgs_results_big_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83ca4212-1273-47d5-a1c8-6ba880ad6c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "      <th>ProductType_AdultMilk</th>\n",
       "      <th>ProductType_BabyMilkPowder</th>\n",
       "      <th>ProductType_Babyfood</th>\n",
       "      <th>ProductType_BeehoonVermicelli</th>\n",
       "      <th>ProductType_BiscuitsCrackersCookies</th>\n",
       "      <th>ProductType_Book</th>\n",
       "      <th>ProductType_BreakfastCereals</th>\n",
       "      <th>ProductType_CannedBakedBeans</th>\n",
       "      <th>...</th>\n",
       "      <th>Weight_400-499g</th>\n",
       "      <th>Weight_500-599g</th>\n",
       "      <th>Weight_600-699g</th>\n",
       "      <th>Weight_700-799g</th>\n",
       "      <th>Weight_800-899g</th>\n",
       "      <th>Weight_900-999g</th>\n",
       "      <th>HalalStatus_Halal</th>\n",
       "      <th>HalalStatus_NonHalal</th>\n",
       "      <th>HealthStatus_Healthy</th>\n",
       "      <th>HealthStatus_NonHealthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>20240123_3_0492.jpg</td>\n",
       "      <td>OtherNoodles_900-999g_NonHalal_NonHealthy</td>\n",
       "      <td>-3.181636</td>\n",
       "      <td>-4.504703</td>\n",
       "      <td>-5.402472</td>\n",
       "      <td>-3.044354</td>\n",
       "      <td>-4.439531</td>\n",
       "      <td>-4.878765</td>\n",
       "      <td>-2.956285</td>\n",
       "      <td>-3.243633</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.679569</td>\n",
       "      <td>-1.524780</td>\n",
       "      <td>0.879020</td>\n",
       "      <td>-2.410152</td>\n",
       "      <td>-1.714454</td>\n",
       "      <td>4.855945</td>\n",
       "      <td>-1.705368</td>\n",
       "      <td>1.654424</td>\n",
       "      <td>-2.420522</td>\n",
       "      <td>2.049949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>20231222_0263.jpg</td>\n",
       "      <td>OtherDriedFood_100-199g_NonHalal_NonHealthy</td>\n",
       "      <td>-3.458481</td>\n",
       "      <td>-3.426337</td>\n",
       "      <td>-3.527550</td>\n",
       "      <td>-2.412646</td>\n",
       "      <td>-1.571299</td>\n",
       "      <td>-2.891962</td>\n",
       "      <td>-2.406638</td>\n",
       "      <td>-3.927027</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.120973</td>\n",
       "      <td>-0.733946</td>\n",
       "      <td>-2.134841</td>\n",
       "      <td>-1.031203</td>\n",
       "      <td>-1.441976</td>\n",
       "      <td>-1.827916</td>\n",
       "      <td>-1.997735</td>\n",
       "      <td>1.786284</td>\n",
       "      <td>-1.699952</td>\n",
       "      <td>1.442010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>IMG_5420_jpeg.rf.bdecaca9965246c4682627af98f1c...</td>\n",
       "      <td>BiscuitsCrackersCookies_100-199g_Halal_NonHealthy</td>\n",
       "      <td>-3.503671</td>\n",
       "      <td>-3.287668</td>\n",
       "      <td>-2.600997</td>\n",
       "      <td>-1.687767</td>\n",
       "      <td>7.061292</td>\n",
       "      <td>-3.095221</td>\n",
       "      <td>-2.792612</td>\n",
       "      <td>-3.632293</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.807092</td>\n",
       "      <td>-1.729294</td>\n",
       "      <td>-1.077936</td>\n",
       "      <td>-1.476647</td>\n",
       "      <td>-1.492334</td>\n",
       "      <td>-1.390535</td>\n",
       "      <td>1.982380</td>\n",
       "      <td>-1.915323</td>\n",
       "      <td>-2.026595</td>\n",
       "      <td>1.700429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>IMG_5438_jpeg.rf.bc5aba94d5ad3d3ee1db710558dbf...</td>\n",
       "      <td>BiscuitsCrackersCookies_300-399g_Halal_NonHealthy</td>\n",
       "      <td>-3.856755</td>\n",
       "      <td>-2.737113</td>\n",
       "      <td>-3.314206</td>\n",
       "      <td>-0.457760</td>\n",
       "      <td>6.340006</td>\n",
       "      <td>-3.908571</td>\n",
       "      <td>-3.668011</td>\n",
       "      <td>-4.602848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522122</td>\n",
       "      <td>-2.509103</td>\n",
       "      <td>-1.624152</td>\n",
       "      <td>-1.068586</td>\n",
       "      <td>-1.120196</td>\n",
       "      <td>-1.543310</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>-0.362309</td>\n",
       "      <td>-2.024193</td>\n",
       "      <td>1.555775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>IMG_5662-1-_jpeg.rf.d08a41798064ddc148cbee7f3e...</td>\n",
       "      <td>InstantNoodles_400-499g_Halal_NonHealthy</td>\n",
       "      <td>-3.276417</td>\n",
       "      <td>-3.028646</td>\n",
       "      <td>-3.449257</td>\n",
       "      <td>-2.736010</td>\n",
       "      <td>-2.179122</td>\n",
       "      <td>-3.175209</td>\n",
       "      <td>-2.873602</td>\n",
       "      <td>-3.705969</td>\n",
       "      <td>...</td>\n",
       "      <td>6.240010</td>\n",
       "      <td>-2.045863</td>\n",
       "      <td>-2.178113</td>\n",
       "      <td>-1.487340</td>\n",
       "      <td>-1.931845</td>\n",
       "      <td>-1.863674</td>\n",
       "      <td>1.296124</td>\n",
       "      <td>-1.845470</td>\n",
       "      <td>-2.147846</td>\n",
       "      <td>1.619118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filepath  \\\n",
       "4453                                20240123_3_0492.jpg   \n",
       "4454                                  20231222_0263.jpg   \n",
       "4455  IMG_5420_jpeg.rf.bdecaca9965246c4682627af98f1c...   \n",
       "4456  IMG_5438_jpeg.rf.bc5aba94d5ad3d3ee1db710558dbf...   \n",
       "4457  IMG_5662-1-_jpeg.rf.d08a41798064ddc148cbee7f3e...   \n",
       "\n",
       "                                                  label  \\\n",
       "4453          OtherNoodles_900-999g_NonHalal_NonHealthy   \n",
       "4454        OtherDriedFood_100-199g_NonHalal_NonHealthy   \n",
       "4455  BiscuitsCrackersCookies_100-199g_Halal_NonHealthy   \n",
       "4456  BiscuitsCrackersCookies_300-399g_Halal_NonHealthy   \n",
       "4457           InstantNoodles_400-499g_Halal_NonHealthy   \n",
       "\n",
       "      ProductType_AdultMilk  ProductType_BabyMilkPowder  ProductType_Babyfood  \\\n",
       "4453              -3.181636                   -4.504703             -5.402472   \n",
       "4454              -3.458481                   -3.426337             -3.527550   \n",
       "4455              -3.503671                   -3.287668             -2.600997   \n",
       "4456              -3.856755                   -2.737113             -3.314206   \n",
       "4457              -3.276417                   -3.028646             -3.449257   \n",
       "\n",
       "      ProductType_BeehoonVermicelli  ProductType_BiscuitsCrackersCookies  \\\n",
       "4453                      -3.044354                            -4.439531   \n",
       "4454                      -2.412646                            -1.571299   \n",
       "4455                      -1.687767                             7.061292   \n",
       "4456                      -0.457760                             6.340006   \n",
       "4457                      -2.736010                            -2.179122   \n",
       "\n",
       "      ProductType_Book  ProductType_BreakfastCereals  \\\n",
       "4453         -4.878765                     -2.956285   \n",
       "4454         -2.891962                     -2.406638   \n",
       "4455         -3.095221                     -2.792612   \n",
       "4456         -3.908571                     -3.668011   \n",
       "4457         -3.175209                     -2.873602   \n",
       "\n",
       "      ProductType_CannedBakedBeans  ...  Weight_400-499g  Weight_500-599g  \\\n",
       "4453                     -3.243633  ...        -1.679569        -1.524780   \n",
       "4454                     -3.927027  ...        -2.120973        -0.733946   \n",
       "4455                     -3.632293  ...        -1.807092        -1.729294   \n",
       "4456                     -4.602848  ...         0.522122        -2.509103   \n",
       "4457                     -3.705969  ...         6.240010        -2.045863   \n",
       "\n",
       "      Weight_600-699g  Weight_700-799g  Weight_800-899g  Weight_900-999g  \\\n",
       "4453         0.879020        -2.410152        -1.714454         4.855945   \n",
       "4454        -2.134841        -1.031203        -1.441976        -1.827916   \n",
       "4455        -1.077936        -1.476647        -1.492334        -1.390535   \n",
       "4456        -1.624152        -1.068586        -1.120196        -1.543310   \n",
       "4457        -2.178113        -1.487340        -1.931845        -1.863674   \n",
       "\n",
       "      HalalStatus_Halal  HalalStatus_NonHalal  HealthStatus_Healthy  \\\n",
       "4453          -1.705368              1.654424             -2.420522   \n",
       "4454          -1.997735              1.786284             -1.699952   \n",
       "4455           1.982380             -1.915323             -2.026595   \n",
       "4456           0.795455             -0.362309             -2.024193   \n",
       "4457           1.296124             -1.845470             -2.147846   \n",
       "\n",
       "      HealthStatus_NonHealthy  \n",
       "4453                 2.049949  \n",
       "4454                 1.442010  \n",
       "4455                 1.700429  \n",
       "4456                 1.555775  \n",
       "4457                 1.619118  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_imgs_results_big_model.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58d0a518-f283-4373-bdc9-0137b9bacf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 98)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_imgs_results_big_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1f7cbc6-94c5-4f86-ae03-576c50ed8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_big_model.to_csv(\"NN_model/regularized/all_imgs_results_big_model.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5249a6c1-6ae9-46a0-9342-531550347eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd022b8e-ce69-4e7d-a467-89eb8f41b453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c74428a-eaae-429e-9d87-2f3256d7f398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08921c6-e648-4b29-8b4d-8c62e2891f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e01a66-4e46-4ae1-b264-6eb99d9d2648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c2e05e-70db-4b6f-835a-8dcd3f7bbc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadResNet_SmallModel(nn.Module):\n",
    "    def __init__(self, num_classes_prdtype, num_classes_weight, num_classes_halal, num_classes_healthy):\n",
    "        super(MultiHeadResNet_SmallModel, self).__init__()\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Identity()\n",
    "\n",
    "        # Define custom fully connected layers for each prediction head\n",
    "        self.fc_prdtype = nn.Linear(num_ftrs, num_classes_prdtype)\n",
    "        self.fc_weight = nn.Linear(num_ftrs, num_classes_weight)\n",
    "        self.fc_halal = nn.Linear(num_ftrs, num_classes_halal)\n",
    "        self.fc_healthy = nn.Linear(num_ftrs, num_classes_healthy)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        prdtype = self.fc_prdtype(x)\n",
    "        weight = self.fc_weight(x)\n",
    "        halal = self.fc_halal(x)\n",
    "        healthy = self.fc_healthy(x)\n",
    "        return prdtype, weight, halal, healthy\n",
    "\n",
    "    \n",
    "# load label encoder \n",
    "def load_label_encoder_small_model():\n",
    "    le_prdtype = pickle.loads(open(\"../small_model/output/le_prdtype.pickle\", \"rb\").read())\n",
    "    le_weight = pickle.loads(open(\"../small_model/output/le_weight.pickle\", \"rb\").read())\n",
    "    le_halal = pickle.loads(open(\"../small_model/output/le_halal.pickle\", \"rb\").read())\n",
    "    le_healthy = pickle.loads(open(\"../small_model/output/le_healthy.pickle\", \"rb\").read())\n",
    "    \n",
    "    return le_prdtype, le_weight, le_halal, le_healthy\n",
    "\n",
    "le_prdtype, le_weight, le_halal, le_healthy = load_label_encoder_small_model()\n",
    "\n",
    "# Load the trained MultiHeadResNet model\n",
    "def load_model():\n",
    "    # Verify the number of classes for each label\n",
    "    num_classes_prdtype = len(le_prdtype.classes_)\n",
    "    num_classes_weight = len(le_weight.classes_)\n",
    "    num_classes_halal = len(le_halal.classes_)\n",
    "    num_classes_healthy = len(le_healthy.classes_)\n",
    "    # print(num_classes_prdtype)\n",
    "    # print(num_classes_healthy)\n",
    "\n",
    "    custom_resnet_model = MultiHeadResNet_SmallModel(\n",
    "        num_classes_prdtype=num_classes_prdtype,\n",
    "        num_classes_weight=num_classes_weight,\n",
    "        num_classes_halal=num_classes_halal,\n",
    "        num_classes_healthy=num_classes_healthy\n",
    "    )\n",
    "\n",
    "    model_path = '../small_model/output/multi_head_model.pth'\n",
    "    # print(\"test1\")\n",
    "    if os.path.exists(model_path):\n",
    "        custom_resnet_model.load_state_dict(torch.load(model_path, map_location=CONFIGS['DEVICE']))\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    # print(\"test2\")\n",
    "    custom_resnet_model.to(CONFIGS['DEVICE'])\n",
    "    custom_resnet_model.eval()\n",
    "    return custom_resnet_model\n",
    " \n",
    "small_model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01625dd-3e23-4cc8-b898-990df6e36051",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_df = pd.read_csv(\"../small_model/new_imgs_list.csv\")\n",
    "new_imgs_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ADHOC: change the new imgs to existing type\n",
    "new_imgs_df['label'] = 'AdultMilk_1-99g_Halal_NonHealthy'\n",
    "new_imgs_df['ProductType'] = 'AdultMilk'\n",
    "new_imgs_df['Weight'] = '1-99g'\n",
    "new_imgs_df['HalalStatus'] = 'Halal'\n",
    "new_imgs_df['HealthStatus'] = 'NonHealthy'\n",
    "\n",
    "new_imgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10219e89-1b08-4aba-8a6b-e7371f767fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_results_small_model = pd.read_csv(\"../small_model/new_imgs_results_small_model.csv\")\n",
    "new_imgs_results_small_model = new_imgs_results_small_model.loc[new_imgs_results_small_model.Filename.isin(new_imgs_df.filepath)]\n",
    "new_imgs_results_small_model.reset_index(drop=True, inplace=True)\n",
    "new_imgs_results_small_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4d6d40-8373-40d2-9f2c-cd1bdf03e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_results_small_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270de8d-3462-4096-a0fc-79ad483c9faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the current column names to a list\n",
    "new_columns = new_imgs_results_small_model.columns.tolist()\n",
    "\n",
    "# Modify the first two elements\n",
    "new_columns[0] = 'filepath'\n",
    "new_columns[1] = 'label'\n",
    "\n",
    "# Assign the modified list of column names back to the DataFrame\n",
    "new_imgs_results_small_model.columns = new_columns\n",
    "new_imgs_results_small_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da044c-3652-47fa-b2a6-29851651a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any name from 'extracted_names' is not in 'df' and add it as a new column\n",
    "new_prdtype = list(set(all_imgs_results_big_model.columns) - set(new_imgs_results_small_model.columns))\n",
    "\n",
    "if len(new_prdtype)>0:\n",
    "    for col in new_prdtype:\n",
    "        new_imgs_results_small_model[col] = np.random.normal(loc=CONFIGS[\"MEAN_PRIOR\"], scale=np.sqrt(0.1), size=new_imgs_results_small_model.shape[0])  # Initialize new columns\n",
    "\n",
    "new_imgs_results_small_model.head()  # Display the updated DataFrame for verificatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a9a54-be7f-44da-809f-8ead58057043",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_results_small_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b835fa19-510a-46da-9e9f-fbc7f17aebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_imgs_master_list = pd.read_csv(\"../master_list.csv\")\n",
    "main_imgs_master_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c9993-4204-4ce8-a94d-d299cc71cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_imgs_results_small_model = []  # List to store the results\n",
    "le_prdtype, le_weight, le_halal, le_healthy = load_label_encoder_small_model()\n",
    "\n",
    "for idx, row in main_imgs_master_list.iterrows():\n",
    "    image_path = \"../all_images/\" + row['filepath']\n",
    "    frame = cv2.imread(image_path)\n",
    "\n",
    "    # Preprocessing steps\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (CONFIGS['SMALL_MODEL_IMG_SIZE'], CONFIGS['SMALL_MODEL_IMG_SIZE']))\n",
    "    frame = frame.transpose((2, 0, 1))\n",
    "    frame = torch.from_numpy(frame).float()\n",
    "    frame = transforms_test(frame).unsqueeze(0).to(CONFIGS['DEVICE'])\n",
    "\n",
    "    # Perform prediction\n",
    "    with torch.no_grad():\n",
    "        out1, out2, out3, out4 = small_model(frame)\n",
    "    \n",
    "    # Extract and store the results\n",
    "    prediction_row = [row['filepath'], row['label']]\n",
    "    prediction_row.extend(out1.cpu().numpy().flatten())\n",
    "    prediction_row.extend(out2.cpu().numpy().flatten())\n",
    "    prediction_row.extend(out3.cpu().numpy().flatten())\n",
    "    prediction_row.extend(out4.cpu().numpy().flatten())\n",
    "    main_imgs_results_small_model.append(prediction_row)\n",
    "\n",
    "\n",
    "# Define column names for the new DataFrame\n",
    "column_names = ['filepath', 'label']\n",
    "column_names += ['ProductType_' + name for name in le_prdtype.classes_]\n",
    "column_names += ['Weight_' + name for name in le_weight.classes_]\n",
    "column_names += ['HalalStatus_' + name for name in le_halal.classes_]\n",
    "column_names += ['HealthStatus_' + name for name in le_healthy.classes_]\n",
    "\n",
    "\n",
    "# Create the DataFrame\n",
    "main_imgs_results_small_model = pd.DataFrame(main_imgs_results_small_model, columns=column_names)\n",
    "main_imgs_results_small_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377fcdd4-51e2-4504-9180-b82559bba314",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_imgs_results_small_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f296f0b-82cb-464e-b6d1-b8305eac4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any name from 'extracted_names' is not in 'df' and add it as a new column\n",
    "new_prdtype = list(set(all_imgs_results_big_model.columns) - set(main_imgs_results_small_model.columns))\n",
    "\n",
    "if len(new_prdtype)>0:\n",
    "    for col in new_prdtype:\n",
    "        main_imgs_results_small_model[col] = np.random.normal(loc=CONFIGS[\"MEAN_PRIOR\"], scale=np.sqrt(0.1), size=main_imgs_results_small_model.shape[0])  # Initialize new columns\n",
    "\n",
    "main_imgs_results_small_model.head()  # Display the updated DataFrame for verificatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da58f23-3ff8-4922-bea5-7cb53385b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_imgs_results_small_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff4b81-3c83-4f14-a4cd-0d6aca30be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_imgs_results_small_model['img_type'] = \"existing\"\n",
    "new_imgs_results_small_model['img_type'] = \"new\"\n",
    "all_imgs_results_small_model = pd.concat([main_imgs_results_small_model, new_imgs_results_small_model], axis=0)\n",
    "all_imgs_results_small_model.reset_index(drop=True, inplace=True)\n",
    "all_imgs_results_small_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ffb233-5daa-4745-acb3-14fbdf01dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_small_model.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9226859-982c-468e-9640-9a736c8c1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_small_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb963e6-89b5-402d-a540-416aac8469e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_small_model.to_csv(\"all_imgs_results_small_model.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801b4e7-3ec9-4905-9ec5-668f144d09a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92848b2e-8591-40d1-9bb7-76e470856395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
