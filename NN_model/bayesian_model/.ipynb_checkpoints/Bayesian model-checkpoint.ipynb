{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8221f-21c5-4d11-9a14-3430af0b2a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision.models import detection, resnet50, ResNet50_Weights\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc75a738-e9c9-4b95-9229-0540fe0a2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = {\n",
    "    # determine the current device and based on that set the pin memory\n",
    "    # flag\n",
    "    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    # specify ImageNet mean and standard deviation\n",
    "    \"IMG_MEAN\": [0.485, 0.456, 0.406],\n",
    "    \"IMG_STD\": [0.229, 0.224, 0.225],\n",
    "    \"MC_DROPOUT_ENABLED\": False,  # Switch to enable/disable MC Dropout for confidence score\n",
    "    \"NUM_DROPOUT_RUNS\": 3,\n",
    "    \"CONFIDENCE_THRESHOLD\": 0,\n",
    "    \"BIG_MODEL_IMG_SIZE\": 320,\n",
    "    \"SMALL_MODEL_IMG_SIZE\": 60,\n",
    "    \"MEAN_PRIOR\": -15,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e0656-aacb-422f-af50-38126e838d71",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Big model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce9ac3-24b6-4306-ae9f-b4d73e4162b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f349c065-57dd-47f2-9043-a91308360219",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadResNet_BigModel(nn.Module):\n",
    "    def __init__(self, num_classes_prdtype, num_classes_weight, num_classes_halal, num_classes_healthy):\n",
    "        super(MultiHeadResNet_BigModel, self).__init__()\n",
    "        self.base_model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        num_ftrs = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Identity()\n",
    "\n",
    "        # Define custom fully connected layers for each prediction head\n",
    "        self.fc_prdtype = nn.Linear(num_ftrs, num_classes_prdtype)\n",
    "        self.fc_weight = nn.Linear(num_ftrs, num_classes_weight)\n",
    "        self.fc_halal = nn.Linear(num_ftrs, num_classes_halal)\n",
    "        self.fc_healthy = nn.Linear(num_ftrs, num_classes_healthy)\n",
    "        self.fc_bbox = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        prdtype = self.fc_prdtype(x)\n",
    "        weight = self.fc_weight(x)\n",
    "        halal = self.fc_halal(x)\n",
    "        healthy = self.fc_healthy(x)\n",
    "        box = self.fc_bbox(x)\n",
    "        return prdtype, weight, halal, healthy, box\n",
    "\n",
    "    \n",
    "# load label encoder \n",
    "def load_label_encoder_big_model():\n",
    "    le_prdtype = pickle.loads(open(\"../big_model/le_prdtype.pickle\", \"rb\").read())\n",
    "    le_weight = pickle.loads(open(\"../big_model/le_weight.pickle\", \"rb\").read())\n",
    "    le_halal = pickle.loads(open(\"../big_model/le_halal.pickle\", \"rb\").read())\n",
    "    le_healthy = pickle.loads(open(\"../big_model/le_healthy.pickle\", \"rb\").read())\n",
    "    \n",
    "    return le_prdtype, le_weight, le_halal, le_healthy\n",
    "\n",
    "le_prdtype, le_weight, le_halal, le_healthy = load_label_encoder_big_model()\n",
    "\n",
    "# Load the trained MultiHeadResNet model\n",
    "def load_model():\n",
    "    # Verify the number of classes for each label\n",
    "    num_classes_prdtype = len(le_prdtype.classes_)\n",
    "    num_classes_weight = len(le_weight.classes_)\n",
    "    num_classes_halal = len(le_halal.classes_)\n",
    "    num_classes_healthy = len(le_healthy.classes_)\n",
    "    # print(num_classes_prdtype)\n",
    "    # print(num_classes_healthy)\n",
    "\n",
    "    custom_resnet_model = MultiHeadResNet_BigModel(\n",
    "        num_classes_prdtype=num_classes_prdtype,\n",
    "        num_classes_weight=num_classes_weight,\n",
    "        num_classes_halal=num_classes_halal,\n",
    "        num_classes_healthy=num_classes_healthy\n",
    "    )\n",
    "\n",
    "    model_path = '../big_model/multi_head_model.pth'\n",
    "    # print(\"test1\")\n",
    "    if os.path.exists(model_path):\n",
    "        custom_resnet_model.load_state_dict(torch.load(model_path, map_location=CONFIGS['DEVICE']))\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    # print(\"test2\")\n",
    "    custom_resnet_model.to(CONFIGS['DEVICE'])\n",
    "    custom_resnet_model.eval()\n",
    "    return custom_resnet_model\n",
    "\n",
    "big_model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa0d993-323b-42cd-b742-bc571f747246",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Scoring on main imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29399c3-77e0-488c-afee-39967ddb641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_imgs_results_big_model = pd.read_csv(\"main_imgs_results_big_model.csv\")\n",
    "main_imgs_results_big_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f98391a-f54d-4251-a8c3-80daa4560e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the current column names to a list\n",
    "new_columns = main_imgs_results_big_model.columns.tolist()\n",
    "\n",
    "# Modify the first two elements\n",
    "new_columns[0] = 'filepath'\n",
    "new_columns[1] = 'label'\n",
    "\n",
    "# Assign the modified list of column names back to the DataFrame\n",
    "main_imgs_results_big_model.columns = new_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c021d2f-ba54-4f2d-a0d0-3e81b2ec8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_model_pred_col_name_original = main_imgs_results_big_model.columns[2:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a540a0-2baa-4f3a-8457-72a21f06b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_results_small_model = pd.read_csv(\"new_imgs_results_small_model.csv\")\n",
    "new_imgs_results_small_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bc085-b969-4cf9-98e7-4c8f0b4b2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract column names that start with 'ProductType'\n",
    "all_prdtypes_new_imgs = [col for col in new_imgs_results_small_model.columns if col.startswith('ProductType')]\n",
    "# all_prdtypes_new_imgs = [col.split('_', 1)[1] for col in all_prdtypes_new_imgs]\n",
    "# all_prdtypes_new_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c2091-daa4-4637-9b6d-2653b582240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any name from 'extracted_names' is not in 'df' and add it as a new column\n",
    "new_prdtype = list(set(all_prdtypes_new_imgs) - set(main_imgs_results_big_model.columns))\n",
    "\n",
    "if len(new_prdtype)==1:\n",
    "    main_imgs_results_big_model[new_prdtype[0]] = np.random.normal(loc=CONFIGS[\"MEAN_PRIOR\"], scale=np.sqrt(0.1), size=main_imgs_results_big_model.shape[0])  # Initialize new columns\n",
    "\n",
    "main_imgs_results_big_model.head()  # Display the updated DataFrame for verificatio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79855889-bc7b-4ac6-83b0-21ff404a1220",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Scoring on new imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638f976-5416-43be-9e88-db876766869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_df = pd.read_csv(\"../small_model/new_imgs_list.csv\")\n",
    "new_imgs_df.reset_index(drop=True, inplace=True)\n",
    "new_imgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff0834-2729-458c-a450-ebab96889095",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_test = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=CONFIGS['IMG_MEAN'], std=CONFIGS['IMG_STD'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6320c-d0c1-4ed6-940c-9b0b74b5b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_results_big_model = []  # List to store the results\n",
    "\n",
    "for idx, row in new_imgs_df.iterrows():\n",
    "    image_path = \"../small_model/new_imgs/\" + row['filepath']\n",
    "    frame = cv2.imread(image_path)\n",
    "\n",
    "    # Preprocessing steps\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (CONFIGS['BIG_MODEL_IMG_SIZE'], CONFIGS['BIG_MODEL_IMG_SIZE']))\n",
    "    frame = frame.transpose((2, 0, 1))\n",
    "    frame = torch.from_numpy(frame).float()\n",
    "    frame = transforms_test(frame).unsqueeze(0).to(CONFIGS['DEVICE'])\n",
    "\n",
    "    # Perform prediction\n",
    "    with torch.no_grad():\n",
    "        out1, out2, out3, out4, _ = big_model(frame)\n",
    "\n",
    "    # Extract and store the results\n",
    "    prediction_row = [row['filepath'], row['label']]\n",
    "    prediction_row.extend(out1.cpu().numpy().flatten())\n",
    "    prediction_row.extend(out2.cpu().numpy().flatten())\n",
    "    prediction_row.extend(out3.cpu().numpy().flatten())\n",
    "    prediction_row.extend(out4.cpu().numpy().flatten())\n",
    "    new_imgs_results_big_model.append(prediction_row)\n",
    "\n",
    "\n",
    "# Define column names for the new DataFrame\n",
    "column_names = ['filepath', 'label']\n",
    "column_names += big_model_pred_col_name_original\n",
    "\n",
    "# Create the DataFrame\n",
    "new_imgs_results_big_model = pd.DataFrame(new_imgs_results_big_model, columns=column_names)\n",
    "new_imgs_results_big_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64815a97-84b8-4fc9-b2e1-1e0488b944f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_results_big_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e76db11-e797-4b47-bfe4-2f3d8f280eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(new_prdtype)==1:\n",
    "    new_imgs_results_big_model[new_prdtype[0]] = np.random.normal(loc=CONFIGS[\"MEAN_PRIOR\"], scale=np.sqrt(0.1), size=new_imgs_results_big_model.shape[0])  # Initialize new columns\n",
    "\n",
    "new_imgs_results_big_model.head()  # Display the updated DataFrame for verificatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c0549-1072-4b8d-8ff9-9ac9cabdfe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_results_big_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20eed6-5f1f-48b7-8397-a0164498189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_imgs_results_big_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe5621-33fa-440c-8451-43ce13bcd1eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## All scorings from big model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6720b1d-00d1-4f93-8b73-c52711f06664",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_big_model = pd.concat([main_imgs_results_big_model, new_imgs_results_big_model], axis=0)\n",
    "all_imgs_results_big_model.reset_index(drop=True, inplace=True)\n",
    "all_imgs_results_big_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca4212-1273-47d5-a1c8-6ba880ad6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_big_model.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d0a518-f283-4373-bdc9-0137b9bacf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_big_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7cbc6-94c5-4f86-ae03-576c50ed8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_big_model.to_csv(\"all_imgs_results_big_model.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c686367-b04b-4844-a4df-588bb21a5f74",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Small model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ddd9d9-7ec2-479c-8c15-d30a0aa86706",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c2e05e-70db-4b6f-835a-8dcd3f7bbc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadResNet_SmallModel(nn.Module):\n",
    "    def __init__(self, num_classes_prdtype, num_classes_weight, num_classes_halal, num_classes_healthy):\n",
    "        super(MultiHeadResNet_SmallModel, self).__init__()\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Identity()\n",
    "\n",
    "        # Define custom fully connected layers for each prediction head\n",
    "        self.fc_prdtype = nn.Linear(num_ftrs, num_classes_prdtype)\n",
    "        self.fc_weight = nn.Linear(num_ftrs, num_classes_weight)\n",
    "        self.fc_halal = nn.Linear(num_ftrs, num_classes_halal)\n",
    "        self.fc_healthy = nn.Linear(num_ftrs, num_classes_healthy)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        prdtype = self.fc_prdtype(x)\n",
    "        weight = self.fc_weight(x)\n",
    "        halal = self.fc_halal(x)\n",
    "        healthy = self.fc_healthy(x)\n",
    "        return prdtype, weight, halal, healthy\n",
    "\n",
    "    \n",
    "# load label encoder \n",
    "def load_label_encoder_small_model():\n",
    "    le_prdtype = pickle.loads(open(\"../small_model/output/le_prdtype.pickle\", \"rb\").read())\n",
    "    le_weight = pickle.loads(open(\"../small_model/output/le_weight.pickle\", \"rb\").read())\n",
    "    le_halal = pickle.loads(open(\"../small_model/output/le_halal.pickle\", \"rb\").read())\n",
    "    le_healthy = pickle.loads(open(\"../small_model/output/le_healthy.pickle\", \"rb\").read())\n",
    "    \n",
    "    return le_prdtype, le_weight, le_halal, le_healthy\n",
    "\n",
    "le_prdtype, le_weight, le_halal, le_healthy = load_label_encoder_small_model()\n",
    "\n",
    "# Load the trained MultiHeadResNet model\n",
    "def load_model():\n",
    "    # Verify the number of classes for each label\n",
    "    num_classes_prdtype = len(le_prdtype.classes_)\n",
    "    num_classes_weight = len(le_weight.classes_)\n",
    "    num_classes_halal = len(le_halal.classes_)\n",
    "    num_classes_healthy = len(le_healthy.classes_)\n",
    "    # print(num_classes_prdtype)\n",
    "    # print(num_classes_healthy)\n",
    "\n",
    "    custom_resnet_model = MultiHeadResNet_SmallModel(\n",
    "        num_classes_prdtype=num_classes_prdtype,\n",
    "        num_classes_weight=num_classes_weight,\n",
    "        num_classes_halal=num_classes_halal,\n",
    "        num_classes_healthy=num_classes_healthy\n",
    "    )\n",
    "\n",
    "    model_path = '../small_model/output/multi_head_model.pth'\n",
    "    # print(\"test1\")\n",
    "    if os.path.exists(model_path):\n",
    "        custom_resnet_model.load_state_dict(torch.load(model_path, map_location=CONFIGS['DEVICE']))\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    # print(\"test2\")\n",
    "    custom_resnet_model.to(CONFIGS['DEVICE'])\n",
    "    custom_resnet_model.eval()\n",
    "    return custom_resnet_model\n",
    " \n",
    "small_model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f318846-b081-48c2-90ed-6a68323af3fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scoring on new imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01625dd-3e23-4cc8-b898-990df6e36051",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_df = pd.read_csv(\"../small_model/new_imgs_list.csv\")\n",
    "new_imgs_df.reset_index(drop=True, inplace=True)\n",
    "new_imgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10219e89-1b08-4aba-8a6b-e7371f767fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_results_small_model = pd.read_csv(\"../small_model/new_imgs_results_small_model.csv\")\n",
    "new_imgs_results_small_model = new_imgs_results_small_model.loc[new_imgs_results_small_model.Filename.isin(new_imgs_df.filepath)]\n",
    "new_imgs_results_small_model.reset_index(drop=True, inplace=True)\n",
    "new_imgs_results_small_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4d6d40-8373-40d2-9f2c-cd1bdf03e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_results_small_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270de8d-3462-4096-a0fc-79ad483c9faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the current column names to a list\n",
    "new_columns = new_imgs_results_small_model.columns.tolist()\n",
    "\n",
    "# Modify the first two elements\n",
    "new_columns[0] = 'filepath'\n",
    "new_columns[1] = 'label'\n",
    "\n",
    "# Assign the modified list of column names back to the DataFrame\n",
    "new_imgs_results_small_model.columns = new_columns\n",
    "new_imgs_results_small_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da044c-3652-47fa-b2a6-29851651a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any name from 'extracted_names' is not in 'df' and add it as a new column\n",
    "new_prdtype = list(set(all_imgs_results_big_model.columns) - set(new_imgs_results_small_model.columns))\n",
    "\n",
    "if len(new_prdtype)>0:\n",
    "    for col in new_prdtype:\n",
    "        new_imgs_results_small_model[col] = np.random.normal(loc=CONFIGS[\"MEAN_PRIOR\"], scale=np.sqrt(0.1), size=new_imgs_results_small_model.shape[0])  # Initialize new columns\n",
    "\n",
    "new_imgs_results_small_model.head()  # Display the updated DataFrame for verificatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a9a54-be7f-44da-809f-8ead58057043",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imgs_results_small_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ca455-fcfe-4696-a870-ca33061339aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Scoring on main imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b835fa19-510a-46da-9e9f-fbc7f17aebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_imgs_master_list = pd.read_csv(\"../master_list.csv\")\n",
    "main_imgs_master_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c9993-4204-4ce8-a94d-d299cc71cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_imgs_results_small_model = []  # List to store the results\n",
    "le_prdtype, le_weight, le_halal, le_healthy = load_label_encoder_small_model()\n",
    "\n",
    "for idx, row in main_imgs_master_list.iterrows():\n",
    "    image_path = \"../all_images/\" + row['filepath']\n",
    "    frame = cv2.imread(image_path)\n",
    "\n",
    "    # Preprocessing steps\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (CONFIGS['SMALL_MODEL_IMG_SIZE'], CONFIGS['SMALL_MODEL_IMG_SIZE']))\n",
    "    frame = frame.transpose((2, 0, 1))\n",
    "    frame = torch.from_numpy(frame).float()\n",
    "    frame = transforms_test(frame).unsqueeze(0).to(CONFIGS['DEVICE'])\n",
    "\n",
    "    # Perform prediction\n",
    "    with torch.no_grad():\n",
    "        out1, out2, out3, out4 = small_model(frame)\n",
    "    \n",
    "    # Extract and store the results\n",
    "    prediction_row = [row['filepath'], row['label']]\n",
    "    prediction_row.extend(out1.cpu().numpy().flatten())\n",
    "    prediction_row.extend(out2.cpu().numpy().flatten())\n",
    "    prediction_row.extend(out3.cpu().numpy().flatten())\n",
    "    prediction_row.extend(out4.cpu().numpy().flatten())\n",
    "    main_imgs_results_small_model.append(prediction_row)\n",
    "\n",
    "\n",
    "# Define column names for the new DataFrame\n",
    "column_names = ['filepath', 'label']\n",
    "column_names += ['ProductType_' + name for name in le_prdtype.classes_]\n",
    "column_names += ['Weight_' + name for name in le_weight.classes_]\n",
    "column_names += ['HalalStatus_' + name for name in le_halal.classes_]\n",
    "column_names += ['HealthStatus_' + name for name in le_healthy.classes_]\n",
    "\n",
    "\n",
    "# Create the DataFrame\n",
    "main_imgs_results_small_model = pd.DataFrame(main_imgs_results_small_model, columns=column_names)\n",
    "main_imgs_results_small_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377fcdd4-51e2-4504-9180-b82559bba314",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_imgs_results_small_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f296f0b-82cb-464e-b6d1-b8305eac4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any name from 'extracted_names' is not in 'df' and add it as a new column\n",
    "new_prdtype = list(set(all_imgs_results_big_model.columns) - set(main_imgs_results_small_model.columns))\n",
    "\n",
    "if len(new_prdtype)>0:\n",
    "    for col in new_prdtype:\n",
    "        main_imgs_results_small_model[col] = np.random.normal(loc=CONFIGS[\"MEAN_PRIOR\"], scale=np.sqrt(0.1), size=main_imgs_results_small_model.shape[0])  # Initialize new columns\n",
    "\n",
    "main_imgs_results_small_model.head()  # Display the updated DataFrame for verificatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da58f23-3ff8-4922-bea5-7cb53385b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_imgs_results_small_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b00d34-dbc1-4735-bb54-0cd641f53938",
   "metadata": {
    "tags": []
   },
   "source": [
    "## All scorings from small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff4b81-3c83-4f14-a4cd-0d6aca30be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_small_model = pd.concat([main_imgs_results_small_model, new_imgs_results_small_model], axis=0)\n",
    "all_imgs_results_small_model.reset_index(drop=True, inplace=True)\n",
    "all_imgs_results_small_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ffb233-5daa-4745-acb3-14fbdf01dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_small_model.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9226859-982c-468e-9640-9a736c8c1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_small_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb963e6-89b5-402d-a540-416aac8469e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_small_model.to_csv(\"all_imgs_results_small_model.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cf4b5f-c8f0-4bc2-abc4-f682c2b7899f",
   "metadata": {},
   "source": [
    "# Bayesian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "739054f4-5af5-4c1d-ba5d-b3b9f99b85c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prdtype_cols = [col for col in all_imgs_results_small_model.columns if col.startswith('ProductType_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42bf121a-9b3b-491e-aede-2622084145ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_small_model_prdtype = all_imgs_results_small_model[['label']+prdtype_cols]\n",
    "all_imgs_results_big_model_prdtype = all_imgs_results_big_model[['label']+prdtype_cols]\n",
    "all_imgs_results_small_model_prdtype = all_imgs_results_small_model_prdtype.sort_values(by='label').reset_index(drop=True)\n",
    "all_imgs_results_big_model_prdtype = all_imgs_results_big_model_prdtype.sort_values(by='label').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8704ee86-1d62-4d63-b57e-6d642b4003c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (all_imgs_results_small_model_prdtype['label'][(all_imgs_results_small_model_prdtype['label'] == all_imgs_results_big_model_prdtype['label'])]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b12ccb1-e5b7-4935-afd2-2cc703e1a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_results_small_model_prdtype['label_prdtype'] = all_imgs_results_small_model_prdtype['label'].str.split('_').str[0]\n",
    "all_imgs_results_big_model_prdtype['label_prdtype'] = all_imgs_results_big_model_prdtype['label'].str.split('_').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "149f1647-6a47-4f9d-ae45-849ba45f2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the prefix from column names\n",
    "all_imgs_results_small_model_prdtype.columns = [col.replace(\"ProductType_\", '') if col.startswith(\"ProductType_\") else col for col in all_imgs_results_small_model_prdtype.columns]\n",
    "all_imgs_results_big_model_prdtype.columns = [col.replace(\"ProductType_\", '') if col.startswith(\"ProductType_\") else col for col in all_imgs_results_big_model_prdtype.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b12c7d4-bb78-4f0b-ab3a-e9d6edd09b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "prdtype_label_encoder = LabelEncoder()\n",
    "truelabel = prdtype_label_encoder.fit_transform(all_imgs_results_big_model_prdtype['label_prdtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "239ec726-def7-4589-a89d-3d67be777b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'category_names' is the list of unique category names in the order they appear in logitscoresA\n",
    "category_names = list(all_imgs_results_small_model_prdtype['label_prdtype'].unique())\n",
    "category_to_encoded = {name: prdtype_label_encoder.transform([name])[0] for name in category_names}\n",
    "\n",
    "# Reorder columns of logitscoresA and logitscoresB to match the order of encoded labels\n",
    "ordered_columns = [category_names[i] for i in prdtype_label_encoder.transform(category_names)]\n",
    "logitscoresA = all_imgs_results_big_model_prdtype[ordered_columns].values\n",
    "logitscoresB = all_imgs_results_small_model_prdtype[ordered_columns].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37975bc7-06ff-4ad7-b09a-21f4bb6b39b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "      <th>ProductType_AdultMilk</th>\n",
       "      <th>ProductType_Babyfood</th>\n",
       "      <th>ProductType_Babymilk-powder</th>\n",
       "      <th>ProductType_BeehoonVermicelliMeesua</th>\n",
       "      <th>ProductType_BiscuitsCrackersCookies</th>\n",
       "      <th>ProductType_Book</th>\n",
       "      <th>ProductType_Breakfast-cereals-cornflakes</th>\n",
       "      <th>ProductType_Canned-Packet-Creamers-Sweet</th>\n",
       "      <th>...</th>\n",
       "      <th>Weight_500-599g</th>\n",
       "      <th>Weight_600-699g</th>\n",
       "      <th>Weight_700-799g</th>\n",
       "      <th>Weight_800-899g</th>\n",
       "      <th>Weight_900-999g</th>\n",
       "      <th>HalalStatus_Halal</th>\n",
       "      <th>HalalStatus_NonHalal</th>\n",
       "      <th>HealthStatus_Healthy</th>\n",
       "      <th>HealthStatus_NonHealthy</th>\n",
       "      <th>ProductType_JennyBakery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20231215_output_frame_0244</td>\n",
       "      <td>PotatoSticks_1-99g_Halal_NonHealthy</td>\n",
       "      <td>-1.587444</td>\n",
       "      <td>-2.496907</td>\n",
       "      <td>-3.559909</td>\n",
       "      <td>-2.273423</td>\n",
       "      <td>1.671694</td>\n",
       "      <td>-0.490730</td>\n",
       "      <td>-3.641042</td>\n",
       "      <td>-2.682706</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.938856</td>\n",
       "      <td>-3.626286</td>\n",
       "      <td>-2.632926</td>\n",
       "      <td>-4.078401</td>\n",
       "      <td>-3.550343</td>\n",
       "      <td>2.026452</td>\n",
       "      <td>-3.092768</td>\n",
       "      <td>-3.751043</td>\n",
       "      <td>2.996024</td>\n",
       "      <td>-19.986669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>output_frame_0617</td>\n",
       "      <td>Kaya_400-499g_Halal_NonHealthy</td>\n",
       "      <td>-4.127325</td>\n",
       "      <td>-1.533400</td>\n",
       "      <td>-1.689596</td>\n",
       "      <td>-1.041802</td>\n",
       "      <td>-1.024461</td>\n",
       "      <td>-4.602612</td>\n",
       "      <td>-2.558664</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.308213</td>\n",
       "      <td>-4.263793</td>\n",
       "      <td>-2.572152</td>\n",
       "      <td>-3.962276</td>\n",
       "      <td>-3.851224</td>\n",
       "      <td>4.229371</td>\n",
       "      <td>-4.268166</td>\n",
       "      <td>-4.517332</td>\n",
       "      <td>4.193677</td>\n",
       "      <td>-20.119013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_5422_jpeg.rf.40db706026c5805998a4ef32aaea01bd</td>\n",
       "      <td>BiscuitsCrackersCookies_100-199g_Halal_NonHealthy</td>\n",
       "      <td>-3.575266</td>\n",
       "      <td>-1.385911</td>\n",
       "      <td>-2.772634</td>\n",
       "      <td>-0.931874</td>\n",
       "      <td>7.930703</td>\n",
       "      <td>-4.527698</td>\n",
       "      <td>-3.865532</td>\n",
       "      <td>-3.374679</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.056430</td>\n",
       "      <td>-2.557728</td>\n",
       "      <td>-2.868939</td>\n",
       "      <td>-1.775112</td>\n",
       "      <td>-3.771607</td>\n",
       "      <td>2.320258</td>\n",
       "      <td>-3.072567</td>\n",
       "      <td>-3.815917</td>\n",
       "      <td>3.348428</td>\n",
       "      <td>-19.627854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_9829_JPG.rf.9dcff8b32299bc2d7285db157c38e6d6</td>\n",
       "      <td>OtherNoodles_500-599g_NonHalal_NonHealthy</td>\n",
       "      <td>-3.725879</td>\n",
       "      <td>-4.687295</td>\n",
       "      <td>-3.840399</td>\n",
       "      <td>-1.293027</td>\n",
       "      <td>-0.585406</td>\n",
       "      <td>-5.363570</td>\n",
       "      <td>-4.092983</td>\n",
       "      <td>-4.843928</td>\n",
       "      <td>...</td>\n",
       "      <td>4.860765</td>\n",
       "      <td>-1.201230</td>\n",
       "      <td>-0.325409</td>\n",
       "      <td>-2.343176</td>\n",
       "      <td>-3.916640</td>\n",
       "      <td>-2.494664</td>\n",
       "      <td>2.036901</td>\n",
       "      <td>-4.395383</td>\n",
       "      <td>3.689328</td>\n",
       "      <td>-20.315636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023_10_25_11_52_33_260721</td>\n",
       "      <td>MaternalMilkPowder_600-699g_Halal_NonHealthy</td>\n",
       "      <td>2.656255</td>\n",
       "      <td>0.116325</td>\n",
       "      <td>2.724130</td>\n",
       "      <td>-3.962348</td>\n",
       "      <td>-1.721440</td>\n",
       "      <td>-6.606655</td>\n",
       "      <td>-3.900061</td>\n",
       "      <td>-5.223273</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.551353</td>\n",
       "      <td>7.838285</td>\n",
       "      <td>-1.788310</td>\n",
       "      <td>-0.916579</td>\n",
       "      <td>-1.628614</td>\n",
       "      <td>1.992190</td>\n",
       "      <td>-3.352175</td>\n",
       "      <td>-3.212959</td>\n",
       "      <td>2.271578</td>\n",
       "      <td>-20.562292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath  \\\n",
       "0                         20231215_output_frame_0244   \n",
       "1                                  output_frame_0617   \n",
       "2  IMG_5422_jpeg.rf.40db706026c5805998a4ef32aaea01bd   \n",
       "3   IMG_9829_JPG.rf.9dcff8b32299bc2d7285db157c38e6d6   \n",
       "4                         2023_10_25_11_52_33_260721   \n",
       "\n",
       "                                               label  ProductType_AdultMilk  \\\n",
       "0                PotatoSticks_1-99g_Halal_NonHealthy              -1.587444   \n",
       "1                     Kaya_400-499g_Halal_NonHealthy              -4.127325   \n",
       "2  BiscuitsCrackersCookies_100-199g_Halal_NonHealthy              -3.575266   \n",
       "3          OtherNoodles_500-599g_NonHalal_NonHealthy              -3.725879   \n",
       "4       MaternalMilkPowder_600-699g_Halal_NonHealthy               2.656255   \n",
       "\n",
       "   ProductType_Babyfood  ProductType_Babymilk-powder  \\\n",
       "0             -2.496907                    -3.559909   \n",
       "1             -1.533400                    -1.689596   \n",
       "2             -1.385911                    -2.772634   \n",
       "3             -4.687295                    -3.840399   \n",
       "4              0.116325                     2.724130   \n",
       "\n",
       "   ProductType_BeehoonVermicelliMeesua  ProductType_BiscuitsCrackersCookies  \\\n",
       "0                            -2.273423                             1.671694   \n",
       "1                            -1.041802                            -1.024461   \n",
       "2                            -0.931874                             7.930703   \n",
       "3                            -1.293027                            -0.585406   \n",
       "4                            -3.962348                            -1.721440   \n",
       "\n",
       "   ProductType_Book  ProductType_Breakfast-cereals-cornflakes  \\\n",
       "0         -0.490730                                 -3.641042   \n",
       "1         -4.602612                                 -2.558664   \n",
       "2         -4.527698                                 -3.865532   \n",
       "3         -5.363570                                 -4.092983   \n",
       "4         -6.606655                                 -3.900061   \n",
       "\n",
       "   ProductType_Canned-Packet-Creamers-Sweet  ...  Weight_500-599g  \\\n",
       "0                                 -2.682706  ...        -1.938856   \n",
       "1                                  0.078720  ...        -1.308213   \n",
       "2                                 -3.374679  ...        -3.056430   \n",
       "3                                 -4.843928  ...         4.860765   \n",
       "4                                 -5.223273  ...        -1.551353   \n",
       "\n",
       "   Weight_600-699g  Weight_700-799g  Weight_800-899g  Weight_900-999g  \\\n",
       "0        -3.626286        -2.632926        -4.078401        -3.550343   \n",
       "1        -4.263793        -2.572152        -3.962276        -3.851224   \n",
       "2        -2.557728        -2.868939        -1.775112        -3.771607   \n",
       "3        -1.201230        -0.325409        -2.343176        -3.916640   \n",
       "4         7.838285        -1.788310        -0.916579        -1.628614   \n",
       "\n",
       "   HalalStatus_Halal  HalalStatus_NonHalal  HealthStatus_Healthy  \\\n",
       "0           2.026452             -3.092768             -3.751043   \n",
       "1           4.229371             -4.268166             -4.517332   \n",
       "2           2.320258             -3.072567             -3.815917   \n",
       "3          -2.494664              2.036901             -4.395383   \n",
       "4           1.992190             -3.352175             -3.212959   \n",
       "\n",
       "   HealthStatus_NonHealthy  ProductType_JennyBakery  \n",
       "0                 2.996024               -19.986669  \n",
       "1                 4.193677               -20.119013  \n",
       "2                 3.348428               -19.627854  \n",
       "3                 3.689328               -20.315636  \n",
       "4                 2.271578               -20.562292  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_imgs_results_big_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02d3a0e2-3cd1-48d2-a45f-0078644cb0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9798096336890684"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# big model accuracy - total\n",
    "pred_big_model_prdtype = np.argmax(logitscoresA, axis=1)\n",
    "sum(pred_big_model_prdtype == truelabel) / len(truelabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "970e677d-e76f-4dcd-a55d-d7837d7bff2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23853475627343523"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small model accuracy - total\n",
    "pred_small_model_prdtype = np.argmax(logitscoresB, axis=1)\n",
    "sum(pred_small_model_prdtype == truelabel) / len(truelabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31360c6f-1825-4d16-bfe8-45ad06fba02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# big model accuracy - new imgs\n",
    "indices = np.where(truelabel == category_to_encoded['JennyBakery'])\n",
    "sum(pred_big_model_prdtype[indices] == truelabel[indices]) / len(indices[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b25336b0-be21-4cf8-8f72-1107796a15eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small model accuracy - new imgs\n",
    "indices = np.where(truelabel == category_to_encoded['JennyBakery'])\n",
    "sum(pred_small_model_prdtype[indices] == truelabel[indices]) / len(indices[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ad12c1f-f8aa-49dd-a439-b1a8fb9d0dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3467"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(truelabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16709105-18b4-4f8d-825c-ce9824238d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitscoresA.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249d28e-45bb-4be9-a79d-f1da70338287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2ceab37-a7e2-4eca-93c9-47e98b56d620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  app.launch_new_instance()\n",
      "/Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pymc3/model.py:1755: ImputationWarning: Data in truelabel_obs contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "/Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages/deprecat/classic.py:215: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  return wrapped_(*args_, **kwargs_)\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "CompoundStep\n",
      ">NUTS: [labelprob, rho, sigmaB, muB0, muB1, sigmaA, muA0, muA1]\n",
      ">CategoricalGibbsMetropolis: [truelabel_obs_missing]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='871' class='' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      34.84% [871/2500 1:39:05&lt;3:05:19 Sampling chain 0, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "Sampling 1 chain for 500 tune and 371 draw iterations (500 + 371 draws total) took 5946 seconds.\n",
      "The acceptance probability does not match the target. It is 0.9999996489687598, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='371' class='' max='371' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [371/371 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred labels for missing indices: [8, 10, 42]\n"
     ]
    }
   ],
   "source": [
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "# Sample data setup (replace with your actual data)\n",
    "# logitscoresA and logitscoresB are matrices of logit scores for each category from classifiers A and B\n",
    "# truelabel is an already existing 1D array of integers representing the true labels\n",
    "indices = [np.random.choice(100, 3, replace=False)]  # Replace with your indices for missing data\n",
    "\n",
    "N = len(truelabel)\n",
    "L = logitscoresA.shape[1]\n",
    "missingidx = indices[0].tolist()  # Indices of missing data\n",
    "\n",
    "# Initialize truelabel_with_missing with the original truelabel and set missing indices to -1\n",
    "truelabel_with_missing = np.array(truelabel, dtype=np.int)\n",
    "truelabel_with_missing[missingidx] = -1\n",
    "\n",
    "# Mask the missing values\n",
    "masked_truelabel = np.ma.masked_where(truelabel_with_missing == -1, truelabel_with_missing)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Priors\n",
    "    muA1 = pm.Normal('muA1', mu=0, sigma=10)\n",
    "    muA0 = pm.Normal('muA0', mu=0, sigma=10)\n",
    "    sigmaA = pm.Uniform('sigmaA', lower=0.01, upper=1.0)\n",
    "    muB1 = pm.Normal('muB1', mu=0, sigma=10)\n",
    "    muB0 = pm.Normal('muB0', mu=0, sigma=10)\n",
    "    sigmaB = pm.Uniform('sigmaB', lower=0.01, upper=1.0)\n",
    "    rho = pm.Uniform('rho', lower=-1, upper=1)\n",
    "    \n",
    "    # Uniform prior over labels\n",
    "    labelprob = pm.Dirichlet('labelprob', a=tt.ones(L))\n",
    "\n",
    "    # Likelihood\n",
    "    muA = pm.math.switch(tt.eq(tt.arange(L), masked_truelabel[:, None]), muA1, muA0)\n",
    "    muB = pm.math.switch(tt.eq(tt.arange(L), masked_truelabel[:, None]), muB1, muB0)\n",
    "    \n",
    "    logitscoresA_obs = pm.Normal('logitscoresA_obs', mu=muA, sigma=sigmaA, observed=logitscoresA)\n",
    "    logitscoresB_obs = pm.Normal('logitscoresB_obs', mu=muB + rho * (logitscoresA - muA) / sigmaA, sigma=tt.sqrt((1 - rho ** 2) * sigmaB ** 2), observed=logitscoresB)\n",
    "    \n",
    "    # Define the categorical distribution for the true labels\n",
    "    truelabel_obs = pm.Categorical('truelabel_obs', p=labelprob, observed=masked_truelabel)\n",
    "\n",
    "    # Inference\n",
    "    trace = pm.sample(2000, tune=500, cores=1)\n",
    "\n",
    "    # Plotting within the model context\n",
    "    # az.plot_trace(trace)\n",
    "    # plt.show()\n",
    "\n",
    "    # Posterior predictive checks\n",
    "    ppc = pm.sample_posterior_predictive(trace, var_names=['truelabel_obs'])\n",
    "\n",
    "# Process the posterior predictive checks for missing indices\n",
    "infer_labels = []\n",
    "for idx in missingidx:\n",
    "    label_samples = ppc['truelabel_obs'][:, idx]\n",
    "    inferred_label = scipy.stats.mode(label_samples).mode[0]\n",
    "    infer_labels.append(inferred_label)\n",
    "\n",
    "# Output the inferred labels for missing indices\n",
    "print(\"Inferred labels for missing indices:\", infer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b352309a-e584-40f9-9c2d-3c71cf4c08f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 10, 42])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(infer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d624ea4-8c0a-4974-ab42-5aa6a92804af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~np.isin(np.arange(N), missingidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbc64ab8-36dc-4f98-a299-b95ae7a775af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(truelabel, dtype=np.int)[missingidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5cd29d7b-0c43-4fcf-86ca-45c892cf76c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 11,  0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_small_model_prdtype[missingidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f01cff0-0b84-4648-81b7-f63d0af47cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_big_model_prdtype[missingidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb881568-91f6-4380-9837-dd8e5817f247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53, 24, 66]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9e7ee52-8d2a-4713-9b5f-b76d6cf3b5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(371, 3467)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppc['truelabel_obs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801b4e7-3ec9-4905-9ec5-668f144d09a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
