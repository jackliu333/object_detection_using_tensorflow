{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b007457d-c3a7-44c2-a8b5-101c6f09e5d4",
   "metadata": {},
   "source": [
    "### This notebook collects all images from the folder images_new and compile them together. All images will be in one folder under `data`, along with a cleaned master list file `master_file.csv` specifying the coordinates of the bounding box. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4c2e2d-80e2-4049-85c2-3c25fe49c82a",
   "metadata": {},
   "source": [
    "# Collect all images in one folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "176695c5-d239-4cb6-848f-d55626c6d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "def collect_images(source_path, destination_folder):\n",
    "    raw_folder = destination_folder\n",
    "    destination_folder = os.path.join(destination_folder, \"data\")\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    else:\n",
    "        shutil.rmtree(destination_folder)\n",
    "        os.makedirs(destination_folder)\n",
    "        \n",
    "    source_folders = os.listdir(source_path)\n",
    "    \n",
    "    all_csv_files = []\n",
    "\n",
    "    for folder in source_folders:\n",
    "        if folder == '.DS_Store':\n",
    "            continue\n",
    "        \n",
    "        tmp_files = os.listdir(os.path.join(source_path, folder))\n",
    "        \n",
    "        if '.DS_Store' in tmp_files:\n",
    "            tmp_files.remove('.DS_Store')\n",
    "        \n",
    "        # check if train folder is available:\n",
    "        if 'train' not in tmp_files:\n",
    "            print(folder)\n",
    "            print(os.listdir(os.path.join(source_path, folder)))\n",
    "            raise ValueError(\"folder structure wrong\")\n",
    "        \n",
    "        # current folder path\n",
    "        tmp_folder = os.path.join(source_path, folder, 'train')\n",
    "        \n",
    "        # move all files in the train folder to the master data folder\n",
    "        for file in os.listdir(tmp_folder):\n",
    "            tmp_source = os.path.join(tmp_folder, file)\n",
    "            \n",
    "            # Check if the file is an image; move all imgs\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                # Create a new name for the file in case of duplicates\n",
    "                counter = 1\n",
    "                new_name = file\n",
    "                while os.path.exists(os.path.join(destination_folder, new_name)):\n",
    "                    name, ext = os.path.splitext(file)\n",
    "                    new_name = f\"{name}_{counter}{ext}\"\n",
    "                    counter += 1\n",
    "                \n",
    "                destination = os.path.join(destination_folder, new_name)\n",
    "                \n",
    "                # Copy the image to the destination folder\n",
    "                shutil.copy(tmp_source, destination)\n",
    "            \n",
    "            # read csv annotations\n",
    "            if file.endswith('.csv'):\n",
    "                df = pd.read_csv(tmp_source, header=None, names=['filepath', 'xmin', 'ymin', 'xmax', 'ymax', 'label'])\n",
    "                # use the folder name as the img label\n",
    "                df['label'] = folder.rstrip(\"-2\")\n",
    "                df['folder_name'] = folder\n",
    "                all_csv_files.append(df)\n",
    "\n",
    "                num_files = df.shape[0]\n",
    "                \n",
    "        # check if # imgs in the folder match the # in the csv file\n",
    "        tmp_num_img = [file for file in os.listdir(tmp_folder) if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "        if num_files != len(tmp_num_img):\n",
    "            print(tmp_folder)   \n",
    "            raise ValueError(\"folder img # mismatch\")\n",
    "        \n",
    "        # check if there is duplicate file name\n",
    "        all_imgs = os.listdir(destination_folder)\n",
    "        \n",
    "        if len(all_imgs) != len(set(all_imgs)):\n",
    "            raise ValueError(\"got duplicate img file name\")\n",
    "    \n",
    "    # Concatenate all the dataframes\n",
    "    annotations = pd.concat(all_csv_files, ignore_index=True)\n",
    "    annotations.to_csv(os.path.join(raw_folder,\"raw_master_list.csv\"), index=False)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# source folders containing images\n",
    "source_path = '/Users/liupeng/Documents/GitHub/object_detection_using_tensorflow/images_new'\n",
    "\n",
    "# Destination folder where all images will be collected\n",
    "destination_folder = '/Users/liupeng/Documents/GitHub/object_detection_using_tensorflow/images_new_v2' \n",
    "\n",
    "# Collect images\n",
    "collect_images(source_path, destination_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b773a3a8-9672-4a1a-b449-b9958ed79e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # images:  2448\n"
     ]
    }
   ],
   "source": [
    "# summary data\n",
    "print(\"Total # images: \", len(os.listdir(os.path.join(destination_folder,\"data\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5d8710-204f-465e-b843-38cb475b84b3",
   "metadata": {},
   "source": [
    "# Generate xml files to show bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad095e73-0a76-4864-bbac-1dc1fabd2a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "\n",
    "def create_xml(destination_folder, source_folder, filename, xmin, ymin, xmax, ymax):\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    else:\n",
    "        shutil.rmtree(destination_folder)\n",
    "        os.makedirs(destination_folder)\n",
    "    \n",
    "    annotation = ET.Element(\"annotation\")\n",
    "    \n",
    "    # Folder\n",
    "    folder = ET.SubElement(annotation, \"folder\")\n",
    "    folder.text = \"bounding_box\"\n",
    "\n",
    "    # Filename\n",
    "    filename_xml = ET.SubElement(annotation, \"filename\")\n",
    "    filename_xml.text = filename\n",
    "    \n",
    "    # get file size\n",
    "    # Open an image file\n",
    "    with Image.open(os.path.join(source_folder, filename)) as img:\n",
    "        # Fetch image dimensions\n",
    "        width, height = img.size\n",
    "\n",
    "    # print(f\"Width: {width}, Height: {height}\")\n",
    "\n",
    "    # Size\n",
    "    size = ET.SubElement(annotation, \"size\")\n",
    "    width_xml = ET.SubElement(size, \"width\")\n",
    "    width_xml.text = str(width)\n",
    "    height_xml = ET.SubElement(size, \"height\")\n",
    "    height_xml.text = str(height)\n",
    "    depth = ET.SubElement(size, \"depth\")\n",
    "    depth.text = \"3\"\n",
    "\n",
    "    # Object\n",
    "    obj = ET.SubElement(annotation, \"object\")\n",
    "    name = ET.SubElement(obj, \"name\")\n",
    "    name.text = \"object_name\"\n",
    "    pose = ET.SubElement(obj, \"pose\")\n",
    "    pose.text = \"Unspecified\"\n",
    "    truncated = ET.SubElement(obj, \"truncated\")\n",
    "    truncated.text = \"0\"\n",
    "    difficult = ET.SubElement(obj, \"difficult\")\n",
    "    difficult.text = \"0\"\n",
    "\n",
    "    # Bounding Box\n",
    "    bndbox = ET.SubElement(obj, \"bndbox\")\n",
    "    xmin_xml = ET.SubElement(bndbox, \"xmin\")\n",
    "    xmin_xml.text = str(xmin)\n",
    "    ymin_xml = ET.SubElement(bndbox, \"ymin\")\n",
    "    ymin_xml.text = str(ymin)\n",
    "    xmax_xml = ET.SubElement(bndbox, \"xmax\")\n",
    "    xmax_xml.text = str(xmax)\n",
    "    ymax_xml = ET.SubElement(bndbox, \"ymax\")\n",
    "    ymax_xml.text = str(ymax)\n",
    "\n",
    "    # Create the XML file\n",
    "    tree = ET.ElementTree(annotation)\n",
    "    with open(os.path.join(destination_folder,f\"{filename}.xml\"), \"wb\") as fh:\n",
    "        tree.write(fh)\n",
    "\n",
    "# Create XML\n",
    "destination_folder = \"/Users/liupeng/Documents/GitHub/object_detection_using_tensorflow/images_new_v2/data_edit\"\n",
    "source_folder = \"/Users/liupeng/Documents/GitHub/object_detection_using_tensorflow/images_new_v2/data_edit\"\n",
    "filename = \"2023_8_11_11_22_30_553933_png.rf.59102374c2520696d8fe64158b5ccb75.jpg\"\n",
    "xmin, ymin, xmax, ymax = 151, 42, 497, 591\n",
    "create_xml(destination_folder, source_folder, filename, xmin, ymin, xmax, ymax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f051dd9-bd09-41f9-b7d0-fa3aadef9edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d851ab-d876-4460-aec2-ee67c7216914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sugar_400-499g_NonHalal_NonHealthy-2',\n",
       " 'OtherNoodles_700-799g_Halal_NonHealthy-2',\n",
       " 'OtherNoodles_400-499g_Halal_NonHealthy-2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_path = '/Users/liupeng/Documents/GitHub/object_detection_using_tensorflow/images_new/Sugar_400-499g_NonHalal_NonHealthy-2/train'\n",
    "source_folders = os.listdir(source_path)\n",
    "source_folders[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11f2802a-aed8-477b-b043-09fb42859d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/liupeng/Documents/GitHub/object_detection_using_tensorflow/images_new/Sugar_400-499g_NonHalal_NonHealthy-2/train'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(source_path, source_folders[0], 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33a398aa-06c9-4c90-83e1-f5e0cccbf934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMG_20230428_123704_jpg.rf.5fc2415d06061ea102ef125a37bbc88c.jpg',\n",
       " 'IMG_20230428_123521_jpg.rf.1069b402272252862ec686589ee0dc3c.jpg',\n",
       " 'IMG_20230428_123522_jpg.rf.204ff37f497f2dce442c7cc3d291ef78.jpg',\n",
       " 'IMG_20230428_123529_jpg.rf.c757a35ff8715805953ae034409a23cd.jpg',\n",
       " '_annotations.csv',\n",
       " 'IMG_20230428_123520_jpg.rf.57a9c7c075e605c7c691efb1dcf227d8.jpg',\n",
       " 'IMG_20230428_123659_jpg.rf.5e1b6c4caabe48cf36003cb4184ff380.jpg',\n",
       " 'IMG_20230428_123528_jpg.rf.5687b7b914f6d9aa98cadf060d1e3b00.jpg',\n",
       " 'IMG_20230428_123703_jpg.rf.6a9c54175f59238cdc83999cdee6dad4.jpg',\n",
       " 'IMG_20230428_123527_jpg.rf.8dd407b0ee5203fd4a46ddf1e061a37f.jpg',\n",
       " 'IMG_20230428_123708_jpg.rf.141ecd0cefaea75c0b7a5f281475dd6b.jpg']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(source_path, source_folders[0], 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c68fc13-d870-4069-911a-e2dd862c2119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('IMG_20230428_123708_jpg.rf.141ecd0cefaea75c0b7a5f281475dd6b', '.jpg')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.splitext('IMG_20230428_123708_jpg.rf.141ecd0cefaea75c0b7a5f281475dd6b.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "223e0e63-34bd-4ba1-aed8-92ceb7b1e853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1740b1d1-6e81-458f-8d1b-077fd97224a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('/Users/liupeng/Documents/GitHub/object_detection_using_tensorflow/images_new_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20581e6d-b2b5-43e1-912d-14c93cd77072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fb_py38",
   "language": "python",
   "name": "fb_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
