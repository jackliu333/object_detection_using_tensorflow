{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa7ae9-f9cd-492f-8f87-5e0c63ef709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import copy\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7bde29-0d3e-4cc2-b0a4-1f1dcdb63807",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = {\n",
    "    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    # specify ImageNet mean and standard deviation\n",
    "    \"IMG_MEAN\": [0.485, 0.456, 0.406],\n",
    "    \"IMG_STD\": [0.229, 0.224, 0.225],\n",
    "    \"INIT_LR\": 1e-4,\n",
    "    \"NUM_EPOCHS\": 200,\n",
    "    \"BATCH_SIZE\": 16,\n",
    "    # specify the loss weights\n",
    "    \"LABELS_PRDTYPE\": 1.0,\n",
    "    \"LABELS_WEIGHT\": 1.0,\n",
    "    \"LABELS_HALAL\": 1.0,\n",
    "    \"LABELS_HEALTHY\": 1.0,\n",
    "    \"MODEL_PATH\": os.path.sep.join([\"output\", \"detector.pth\"]),\n",
    "    \"LE_PATH_PRDTYPE\": os.path.sep.join([\"output\", \"le_prdtype.pickle\"]),\n",
    "    \"LE_PATH_WEIGHT\": os.path.sep.join([\"output\", \"le_weight.pickle\"]),\n",
    "    \"LE_PATH_HALAL\": os.path.sep.join([\"output\", \"le_halal.pickle\"]),\n",
    "    \"LE_PATH_HEALTHY\": os.path.sep.join([\"output\", \"le_healthy.pickle\"]),\n",
    "    \"PIN_MEMORY\": True if torch.cuda.is_available() else False,\n",
    "    \"DATA_BASE_PATH\": \"/Users/liupeng/Documents/GitHub/object_detection_using_tensorflow/images_combined/all_images\",\n",
    "    \"NEW_DATA_BASE_PATH\": \"/Users/liupeng/Documents/GitHub/object_detection_using_tensorflow/images_combined/small_model/new_imgs\"\n",
    "}\n",
    "\n",
    "# create output folder\n",
    "if not os.path.exists(\"output\"):\n",
    "    !mkdir -p {\"output\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d80f47-b6ca-4064-9752-40c14fbcbd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_1 = pd.read_csv(\"base_imgs_list.csv\")\n",
    "annotations_1.reset_index(drop=True, inplace=True)\n",
    "annotations_1['Type'] = \"old\"\n",
    "\n",
    "annotations_2 = pd.read_csv(\"new_imgs_list.csv\")\n",
    "annotations_2.reset_index(drop=True, inplace=True)\n",
    "annotations_2['Type'] = \"new\"\n",
    "\n",
    "# Concatenate the two dataframes vertically\n",
    "annotations = pd.concat([annotations_1, annotations_2], ignore_index=True)\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2676357-d825-4673-8a99-bb919b2409e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for processed data\n",
    "data, imagePaths, filenames = [], [], []\n",
    "\n",
    "# Process each annotation entry\n",
    "for idx, row in annotations.iterrows():\n",
    "    filepath = row[\"filepath\"]\n",
    "    if row['Type'] == 'old':\n",
    "        imagePath = os.path.join(\"/content\", CONFIGS[\"DATA_BASE_PATH\"], filepath)\n",
    "    else:\n",
    "        imagePath = os.path.join(\"/content\", CONFIGS[\"NEW_DATA_BASE_PATH\"], filepath)\n",
    "    image = cv2.imread(imagePath)\n",
    "    \n",
    "    # Preprocess image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (60, 60))\n",
    "\n",
    "    # Append processed data to lists\n",
    "    data.append(image)\n",
    "    imagePaths.append(imagePath)\n",
    "    # filenames.append(filepath.rsplit('.', 1)[0])\n",
    "    filenames.append(filepath)\n",
    "\n",
    "# Convert data to NumPy arrays for machine learning processing\n",
    "labels = {\n",
    "    'labels_prdtype': annotations['ProductType'],\n",
    "    'labels_weight': annotations['Weight'],\n",
    "    'labels_halal': annotations['HalalStatus'],\n",
    "    'labels_healthy': annotations['HealthStatus'],\n",
    "    'labels_total': annotations['label']\n",
    "}\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "for label_name, label_data in labels.items():\n",
    "    labels[label_name] = np.array(label_data)\n",
    "\n",
    "# Split the data and labels into training and testing sets\n",
    "split = train_test_split(data, *labels.values(), imagePaths, filenames,\n",
    "                         test_size=0.3, random_state=42, stratify=labels['labels_total'])\n",
    "\n",
    "# Unpack the data split\n",
    "(trainImages, testImages, *split_labels, trainPaths, testPaths, trainFilenames, testFilenames) = split\n",
    "\n",
    "# Create label encoders and transform labels\n",
    "le_prdtype = LabelEncoder()\n",
    "le_weight = LabelEncoder()\n",
    "le_halal = LabelEncoder()\n",
    "le_healthy = LabelEncoder()\n",
    "le_total = LabelEncoder()\n",
    "\n",
    "trainLabels = {}\n",
    "testLabels = {}\n",
    "\n",
    "# Fit label encoders and transform labels\n",
    "trainLabels['labels_prdtype'] = le_prdtype.fit_transform(split_labels[0])\n",
    "testLabels['labels_prdtype'] = le_prdtype.transform(split_labels[1])\n",
    "\n",
    "trainLabels['labels_weight'] = le_weight.fit_transform(split_labels[2])\n",
    "testLabels['labels_weight'] = le_weight.transform(split_labels[3])\n",
    "\n",
    "trainLabels['labels_halal'] = le_halal.fit_transform(split_labels[4])\n",
    "testLabels['labels_halal'] = le_halal.transform(split_labels[5])\n",
    "\n",
    "trainLabels['labels_healthy'] = le_healthy.fit_transform(split_labels[6])\n",
    "testLabels['labels_healthy'] = le_healthy.transform(split_labels[7])\n",
    "\n",
    "trainLabels['labels_total'] = le_total.fit_transform(split_labels[8])\n",
    "testLabels['labels_total'] = le_total.transform(split_labels[9])\n",
    "\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "trainImages, testImages = torch.tensor(trainImages), torch.tensor(testImages)\n",
    "for label_name in labels.keys():\n",
    "    trainLabels[label_name] = torch.tensor(trainLabels[label_name])\n",
    "    testLabels[label_name] = torch.tensor(testLabels[label_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b870a-5fab-4f78-8559-b428f64cd1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTensorDataset(Dataset):\n",
    "    # Initialize the constructor\n",
    "    def __init__(self, images, labels, filenames, transforms=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.filenames = filenames\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Grab the image, labels, and its bounding box coordinates\n",
    "        image = self.images[index]\n",
    "        label_prdtype = self.labels['labels_prdtype'][index]\n",
    "        label_weight = self.labels['labels_weight'][index]\n",
    "        label_halal = self.labels['labels_halal'][index]\n",
    "        label_healthy = self.labels['labels_healthy'][index]\n",
    "        filename = self.filenames[index]\n",
    "\n",
    "        # Transpose the image such that its channel dimension becomes the leading one\n",
    "        image = image.permute(2, 0, 1)\n",
    "\n",
    "        # Check to see if we have any image transformations to apply and if so, apply them\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        # Return a tuple of the images, labels, and bounding box coordinates\n",
    "        return (image, label_prdtype, label_weight, label_halal, label_healthy, filename)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the size of the dataset\n",
    "        return len(self.images)\n",
    "\n",
    "# Define normalization and augmentation transforms\n",
    "normalization_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=CONFIGS['IMG_MEAN'], std=CONFIGS['IMG_STD'])\n",
    "])\n",
    "\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.2),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.RandomRotation(20),\n",
    "    # transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1)\n",
    "])\n",
    "\n",
    "# Combine augmentation and normalization for training\n",
    "train_transforms = transforms.Compose([augmentation_transforms, normalization_transforms])\n",
    "test_transforms = normalization_transforms\n",
    "\n",
    "# Create PyTorch datasets\n",
    "trainDS = CustomTensorDataset(trainImages, trainLabels, trainFilenames, transforms=train_transforms)\n",
    "testDS = CustomTensorDataset(testImages, testLabels, testFilenames, transforms=test_transforms)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(\"[INFO] total training samples: {}...\".format(len(trainDS)))\n",
    "print(\"[INFO] total test samples: {}...\".format(len(testDS)))\n",
    "\n",
    "# Calculate steps per epoch for training and validation set\n",
    "trainSteps = len(trainDS) // CONFIGS['BATCH_SIZE']\n",
    "valSteps = len(testDS) // CONFIGS['BATCH_SIZE']\n",
    "\n",
    "# Create data loaders\n",
    "trainLoader = DataLoader(trainDS, batch_size=CONFIGS['BATCH_SIZE'], shuffle=True,\n",
    "                         num_workers=os.cpu_count(), pin_memory=CONFIGS['PIN_MEMORY'])\n",
    "testLoader = DataLoader(testDS, batch_size=CONFIGS['BATCH_SIZE'],\n",
    "                        num_workers=os.cpu_count(), pin_memory=CONFIGS['PIN_MEMORY'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf52af-29f1-4ed4-bc62-24673572e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MultiHeadResNet model\n",
    "class MultiHeadResNet(nn.Module):\n",
    "    def __init__(self, num_classes_prdtype, num_classes_weight, num_classes_halal, num_classes_healthy):\n",
    "        super(MultiHeadResNet, self).__init__()\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Identity()\n",
    "\n",
    "        # Define custom fully connected layers for each prediction head\n",
    "        self.fc_prdtype = nn.Linear(num_ftrs, num_classes_prdtype)\n",
    "        self.fc_weight = nn.Linear(num_ftrs, num_classes_weight)\n",
    "        self.fc_halal = nn.Linear(num_ftrs, num_classes_halal)\n",
    "        self.fc_healthy = nn.Linear(num_ftrs, num_classes_healthy)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        prdtype = self.fc_prdtype(x)\n",
    "        weight = self.fc_weight(x)\n",
    "        halal = self.fc_halal(x)\n",
    "        healthy = self.fc_healthy(x)\n",
    "        return prdtype, weight, halal, healthy\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    corrects = torch.sum(preds == labels.data)\n",
    "    return corrects.double() / labels.size(0)\n",
    "\n",
    "# Training and Validation Loop with Early Stopping\n",
    "def train_model(model, criteria, optimizer, train_loader, test_loader, device, num_epochs=25, early_stopping_patience=10):\n",
    "    criterion_prdtype, criterion_weight, criterion_halal, criterion_healthy = criteria\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc_prdtype': [],\n",
    "        'train_acc_weight': [],\n",
    "        'train_acc_halal': [],\n",
    "        'train_acc_healthy': [],\n",
    "        'train_acc_overall': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc_prdtype': [],\n",
    "        'val_acc_weight': [],\n",
    "        'val_acc_halal': [],\n",
    "        'val_acc_healthy': [],\n",
    "        'val_acc_overall': [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects_prdtype = 0\n",
    "            running_corrects_weight = 0\n",
    "            running_corrects_halal = 0\n",
    "            running_corrects_healthy = 0\n",
    "            running_corrects_overall = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            for inputs, label_prdtype, label_weight, label_halal, label_healthy, _ in train_loader if phase == 'train' else test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                label_prdtype = label_prdtype.to(device)\n",
    "                label_weight = label_weight.to(device)\n",
    "                label_halal = label_halal.to(device)\n",
    "                label_healthy = label_healthy.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs_prdtype, outputs_weight, outputs_halal, outputs_healthy = model(inputs)\n",
    "                    loss_prdtype = criterion_prdtype(outputs_prdtype, label_prdtype)\n",
    "                    loss_weight = criterion_weight(outputs_weight, label_weight)\n",
    "                    loss_halal = criterion_halal(outputs_halal, label_halal)\n",
    "                    loss_healthy = criterion_healthy(outputs_healthy, label_healthy)\n",
    "                    loss = loss_prdtype + loss_weight + loss_halal + loss_healthy  # Total loss\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects_prdtype += calculate_accuracy(outputs_prdtype, label_prdtype) * inputs.size(0)\n",
    "                running_corrects_weight += calculate_accuracy(outputs_weight, label_weight) * inputs.size(0)\n",
    "                running_corrects_halal += calculate_accuracy(outputs_halal, label_halal) * inputs.size(0)\n",
    "                running_corrects_healthy += calculate_accuracy(outputs_healthy, label_healthy) * inputs.size(0)\n",
    "                correct_preds_overall = ((outputs_prdtype.argmax(1) == label_prdtype) &\n",
    "                                         (outputs_weight.argmax(1) == label_weight) &\n",
    "                                         (outputs_halal.argmax(1) == label_halal) &\n",
    "                                         (outputs_healthy.argmax(1) == label_healthy))\n",
    "                running_corrects_overall += correct_preds_overall.sum().item()\n",
    "                total_samples += inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / total_samples\n",
    "            epoch_acc_prdtype = running_corrects_prdtype / total_samples\n",
    "            epoch_acc_weight = running_corrects_weight / total_samples\n",
    "            epoch_acc_halal = running_corrects_halal / total_samples\n",
    "            epoch_acc_healthy = running_corrects_healthy / total_samples\n",
    "            epoch_acc_overall = running_corrects_overall / total_samples\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc_overall))\n",
    "\n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_val_loss:\n",
    "                    print(\"new loss obtained\")\n",
    "                    best_val_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    print(f\"tmp epochs_no_improve: {epochs_no_improve}\")\n",
    "\n",
    "                if epochs_no_improve >= early_stopping_patience:\n",
    "                    print(\"Early stopping triggered at epoch: {}\".format(epoch + 1))\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    return model, history\n",
    "            \n",
    "            print(f\"epochs_no_improve: {epochs_no_improve}\")\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "# Example usage of the function\n",
    "# Assuming CONFIGS, trainLoader, testLoader, etc. are already defined\n",
    "num_classes_prdtype = len(np.unique(trainLabels['labels_prdtype']))\n",
    "num_classes_weight = len(np.unique(trainLabels['labels_weight']))\n",
    "num_classes_halal = len(np.unique(trainLabels['labels_halal']))\n",
    "num_classes_healthy = len(np.unique(trainLabels['labels_healthy']))\n",
    "\n",
    "custom_resnet_model = MultiHeadResNet(num_classes_prdtype, num_classes_weight, num_classes_halal, num_classes_healthy)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "custom_resnet_model = custom_resnet_model.to(device)\n",
    "\n",
    "criterion_prdtype = nn.CrossEntropyLoss()\n",
    "criterion_weight = nn.CrossEntropyLoss()\n",
    "criterion_halal = nn.CrossEntropyLoss()\n",
    "criterion_healthy = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(custom_resnet_model.parameters(), lr=CONFIGS['INIT_LR'])\n",
    "\n",
    "criteria = (criterion_prdtype, criterion_weight, criterion_halal, criterion_healthy)\n",
    "\n",
    "# Start time\n",
    "print(\"Model training started...\")\n",
    "start_time = time.time()\n",
    "\n",
    "model_ft, history = train_model(custom_resnet_model, criteria, optimizer, trainLoader, testLoader, device, num_epochs=CONFIGS['NUM_EPOCHS'])\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "print(\"Model training completed...\")\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Time spent: {round(execution_time/60,2)} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac334ef-1ac8-4172-b75a-59a13b25f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Time spent: {round(execution_time/60,2)} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c51679-7fe1-4459-b105-9692bf06a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), 'output/multi_head_model.pth')\n",
    "\n",
    "print(\"[INFO] saving label encoder...\")\n",
    "f = open(CONFIGS[\"LE_PATH_PRDTYPE\"], \"wb\")\n",
    "f.write(pickle.dumps(le_prdtype))\n",
    "f.close()\n",
    "f = open(CONFIGS[\"LE_PATH_WEIGHT\"], \"wb\")\n",
    "f.write(pickle.dumps(le_weight))\n",
    "f.close()\n",
    "f = open(CONFIGS[\"LE_PATH_HALAL\"], \"wb\")\n",
    "f.write(pickle.dumps(le_halal))\n",
    "f.close()\n",
    "f = open(CONFIGS[\"LE_PATH_HEALTHY\"], \"wb\")\n",
    "f.write(pickle.dumps(le_healthy))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de520c9-41e2-4c11-bed9-67caf2609523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, dataset_size, num_mc_samples=50):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct_counts = {'ProductType': 0, 'Weight': 0, 'HalalStatus': 0, 'HealthStatus': 0, 'Total': 0}\n",
    "    total_distances = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (images, labels_prdtype, labels_weight, labels_halal, labels_healthy, filenames) in data_loader:\n",
    "            images = images.to(CONFIGS['DEVICE'])\n",
    "            labels_prdtype, labels_weight, labels_halal, labels_healthy = labels_prdtype.to(CONFIGS['DEVICE']), labels_weight.to(CONFIGS['DEVICE']), labels_halal.to(CONFIGS['DEVICE']), labels_healthy.to(CONFIGS['DEVICE'])\n",
    "\n",
    "            # Forward pass\n",
    "            out1, out2, out3, out4 = model(images)\n",
    "\n",
    "            # Store deterministic predictions\n",
    "            det_pred_prdtype = out1.argmax(1)\n",
    "            det_pred_weight = out2.argmax(1)\n",
    "            det_pred_halal = out3.argmax(1)\n",
    "            det_pred_healthy = out4.argmax(1)\n",
    "\n",
    "            # # Monte Carlo Dropout\n",
    "            # mc_distances = []\n",
    "            # model.train()  # Enable dropout\n",
    "            # for i in range(num_mc_samples):\n",
    "            #     mc_out1, mc_out2, mc_out3, mc_out4, _ = model(images)\n",
    "            #     mc_pred_prdtype = mc_out1.argmax(1)\n",
    "            #     mc_pred_weight = mc_out2.argmax(1)\n",
    "            #     mc_pred_halal = mc_out3.argmax(1)\n",
    "            #     mc_pred_healthy = mc_out4.argmax(1)\n",
    "\n",
    "            #     distance = (det_pred_prdtype != mc_pred_prdtype).float() + \\\n",
    "            #                (det_pred_weight != mc_pred_weight).float() + \\\n",
    "            #                (det_pred_halal != mc_pred_halal).float() + \\\n",
    "            #                (det_pred_healthy != mc_pred_healthy).float()\n",
    "\n",
    "            #     mc_distances.append(distance)\n",
    "\n",
    "            # # Calculate average distance\n",
    "            # avg_distance = torch.stack(mc_distances).mean(0)\n",
    "            # total_distances.extend(avg_distance.cpu().numpy().tolist())\n",
    "\n",
    "            # Restore to evaluation mode\n",
    "            # model.eval()\n",
    "\n",
    "            # Update correct counts for each category\n",
    "            correct_counts['ProductType'] += (out1.argmax(1) == labels_prdtype).float().sum().item()\n",
    "            correct_counts['Weight'] += (out2.argmax(1) == labels_weight).float().sum().item()\n",
    "            correct_counts['HalalStatus'] += (out3.argmax(1) == labels_halal).float().sum().item()\n",
    "            correct_counts['HealthStatus'] += (out4.argmax(1) == labels_healthy).float().sum().item()\n",
    "            correct_counts['Total'] += ((out1.argmax(1) == labels_prdtype) & (out2.argmax(1) == labels_weight) & (out3.argmax(1) == labels_halal) & (out4.argmax(1) == labels_healthy)).float().sum().item()\n",
    "\n",
    "    # Calculate accuracies\n",
    "    accuracies = {key: correct_counts[key] / dataset_size for key in correct_counts}\n",
    "    # avg_total_distance = sum(total_distances) / len(total_distances)\n",
    "\n",
    "    # Plot histogram of distances\n",
    "    # plt.hist(total_distances, bins=30, alpha=0.7, label='Total Distances', color='b')\n",
    "    # plt.xlabel('Distance')\n",
    "    # plt.ylabel('Frequency')\n",
    "    # plt.title(f'Distribution of Total Distances: N={len(total_distances)}')\n",
    "    # plt.show()\n",
    "\n",
    "    # return accuracies, avg_total_distance, total_distances\n",
    "    return accuracies\n",
    "\n",
    "# Evaluate on training set\n",
    "train_accuracies = evaluate_model(model_ft, trainLoader, len(trainDS))\n",
    "print(f\"Training Accuracies: {train_accuracies}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_accuracies= evaluate_model(model_ft, testLoader, len(testDS))\n",
    "print(f\"Test Accuracies: {test_accuracies}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911e938-4e3e-4d1c-b7a7-79ea6b2d7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model2(model, data_loader, le_prdtype, le_weight, le_halal, le_healthy):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    results = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (images, labels_prdtype, labels_weight, labels_halal, labels_healthy, filenames) in data_loader:\n",
    "            images = images.to(CONFIGS['DEVICE'])\n",
    "            out1, out2, out3, out4 = model(images)\n",
    "\n",
    "            for idx in range(len(filenames)):\n",
    "                correct_label = f\"{le_prdtype.classes_[labels_prdtype[idx]]}_{le_weight.classes_[labels_weight[idx]]}_{le_halal.classes_[labels_halal[idx]]}_{le_healthy.classes_[labels_healthy[idx]]}\"\n",
    "                row = [filenames[idx], correct_label]\n",
    "                row.extend(out1[idx].cpu().numpy())\n",
    "                row.extend(out2[idx].cpu().numpy())\n",
    "                row.extend(out3[idx].cpu().numpy())\n",
    "                row.extend(out4[idx].cpu().numpy())\n",
    "                results.append(row)\n",
    "\n",
    "    # Define column names\n",
    "    column_names = ['Filename', 'CorrectTotalLabel']\n",
    "    column_names += ['ProductType_' + name for name in le_prdtype.classes_]\n",
    "    column_names += ['Weight_' + name for name in le_weight.classes_]\n",
    "    column_names += ['HalalStatus_' + name for name in le_halal.classes_]\n",
    "    column_names += ['HealthStatus_' + name for name in le_healthy.classes_]\n",
    "\n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame(results, columns=column_names)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Usage of the function\n",
    "train_results_df = evaluate_model2(model_ft, trainLoader, le_prdtype, le_weight, le_halal, le_healthy)\n",
    "test_results_df = evaluate_model2(model_ft, testLoader, le_prdtype, le_weight, le_halal, le_healthy)\n",
    "\n",
    "# Concatenate the training and test results\n",
    "combined_results_df = pd.concat([train_results_df, test_results_df], axis=0)\n",
    "combined_results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the combined results\n",
    "print(\"Combined Results:\")\n",
    "combined_results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c7f644-2873-424e-a5d0-a5449bc59145",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results_df.to_csv('new_imgs_results_small_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3dfc17-58da-4629-ac6d-5b3b79cf68b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc09a3-dc99-430b-9191-ad921bae3108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f73dcb-5826-4883-8db9-4597a6029a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292ad04-327e-4c81-9f06-4cde6bcc4d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f67b0-153b-43ae-98c0-3089dfb4695a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae15a2d4-c1a8-45f9-b9c1-3f7654d15285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac763cb0-09bf-49dc-bad0-ca99b577e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Since the actual data is an image of text, we'll manually transcribe a few lines to demonstrate the process.\n",
    "# In practice, the user would extract the text data using OCR (Optical Character Recognition) tools such as Tesseract.\n",
    "\n",
    "\n",
    "# Convert the example data into a DataFrame\n",
    "df = pd.read_csv(\"./results_[0.1].csv\")\n",
    "\n",
    "# Flatten the list of lists into a single list\n",
    "all_indices = [i for sublist in df['Alpha Max Indices'] for i in sublist]\n",
    "\n",
    "# Count the frequency of each number\n",
    "frequency_counts = Counter(all_indices)\n",
    "\n",
    "frequency_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff025fa-23be-4979-a298-6bd8ecc42a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
